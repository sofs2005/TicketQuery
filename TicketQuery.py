import requests
import openai
import re
import plugins
import os
import json
from plugins import *
from bridge.context import ContextType
from bridge.reply import Reply, ReplyType
from common.log import logger
from datetime import datetime, timedelta
from collections import defaultdict
import traceback

# OpenAIé…ç½®
OPENAI_API_KEY = None  # ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½
OPENAI_API_BASE = "https://api.openai.com/v1"  # é»˜è®¤APIåŸºç¡€URL
OPENAI_MODEL = "gpt-3.5-turbo"  # é»˜è®¤æ¨¡å‹
OPENAI_API_VERSION = "v1"  # é»˜è®¤APIç‰ˆæœ¬
USE_OPENAI = False  # æ˜¯å¦ä½¿ç”¨OpenAIç­›é€‰åŠŸèƒ½

# é¢„å®šä¹‰çƒ­é—¨ä¸­è½¬ç«™æ˜ å°„
TRANSFER_STATIONS = {
    # æ ¼å¼ï¼š("å‡ºå‘åŸå¸‚", "ç›®çš„åŸå¸‚"): ["ä¸­è½¬ç«™1", "ä¸­è½¬ç«™2", ...]
    ("æˆéƒ½", "ä¸Šæµ·"): ["æ­¦æ±‰", "éƒ‘å·", "å—äº¬"],
    ("åŒ—äº¬", "å¹¿å·"): ["éƒ‘å·", "æ­¦æ±‰", "é•¿æ²™"],
    ("è¥¿å®‰", "ä¸Šæµ·"): ["éƒ‘å·", "åˆè‚¥"],
    ("åŒ—äº¬", "æˆéƒ½"): ["éƒ‘å·", "è¥¿å®‰"],
    ("å¹¿å·", "åŒ—äº¬"): ["æ­¦æ±‰", "éƒ‘å·"],
    ("ä¸Šæµ·", "æˆéƒ½"): ["æ­¦æ±‰", "é‡åº†"],
    ("æ·±åœ³", "åŒ—äº¬"): ["é•¿æ²™", "æ­¦æ±‰", "éƒ‘å·"],
    ("é‡åº†", "ä¸Šæµ·"): ["æ­¦æ±‰", "åˆè‚¥"],
    ("æ­å·", "æˆéƒ½"): ["æ­¦æ±‰", "é‡åº†"],
    ("æˆéƒ½", "æ­å·"): ["é‡åº†", "æ­¦æ±‰"]
}

# å…¨å›½ä¸»è¦é“è·¯æ¢çº½ç«™ï¼ˆç”¨äºåŠ¨æ€è®¡ç®—ä¸­è½¬ï¼‰
MAJOR_STATIONS = [
    "åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "å—äº¬", "æ­¦æ±‰", 
    "éƒ‘å·", "è¥¿å®‰", "æˆéƒ½", "é‡åº†", "é•¿æ²™", "åˆè‚¥", "æµå—",
    "å¤©æ´¥", "æ²ˆé˜³", "å“ˆå°”æ»¨", "å¤ªåŸ", "å…°å·", "å—æ˜Œ", "æ˜†æ˜",
    "ç¦å·", "å¦é—¨", "å®æ³¢", "é’å²›", "å¤§è¿", "è´µé˜³"
]

# å°è¯•ä»æ’ä»¶ç›®å½•åŠ è½½é…ç½®
try:
    plugin_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(plugin_dir, "config.json")
    logger.info(f"å°è¯•ä» {config_path} åŠ è½½é…ç½®")
    
    if os.path.exists(config_path):
        logger.info(f"é…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•è¯»å–å†…å®¹")
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                file_content = f.read()
                logger.info(f"è¯»å–åˆ°é…ç½®æ–‡ä»¶å†…å®¹: {file_content[:100]}...")
                plugin_config = json.loads(file_content)
                
            logger.info(f"é…ç½®æ–‡ä»¶è§£æç»“æœ: {json.dumps(plugin_config, ensure_ascii=False)}")
            
            OPENAI_API_KEY = plugin_config.get("open_ai_api_key")
            if OPENAI_API_KEY:
                OPENAI_API_BASE = plugin_config.get("open_ai_api_base", OPENAI_API_BASE)
                OPENAI_MODEL = plugin_config.get("open_ai_model", OPENAI_MODEL)
                # æ£€æŸ¥APIç‰ˆæœ¬é…ç½®
                OPENAI_API_VERSION = plugin_config.get("open_ai_api_version", OPENAI_API_VERSION)
                logger.info(f"æ£€æµ‹åˆ°APIç‰ˆæœ¬é…ç½®: {OPENAI_API_VERSION}")
                USE_OPENAI = True
                logger.info(f"ä»æ’ä»¶é…ç½®åŠ è½½OpenAIè®¾ç½®æˆåŠŸï¼APIå¯†é’¥: {OPENAI_API_KEY[:8]}..., APIåŸºç¡€URL: {OPENAI_API_BASE}, æ¨¡å‹: {OPENAI_MODEL}, APIç‰ˆæœ¬: {OPENAI_API_VERSION}")
            else:
                logger.warning("æ’ä»¶é…ç½®ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        except Exception as read_error:
            logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å‡ºé”™: {read_error}")
            logger.error(traceback.format_exc())
    else:
        logger.warning(f"æ’ä»¶é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
    # å¦‚æœæ’ä»¶é…ç½®ä¸å¯ç”¨ï¼Œå°è¯•ä»å…¨å±€é…ç½®åŠ è½½
    if not USE_OPENAI:
        logger.info("æ’ä»¶é…ç½®ä¸å¯ç”¨ï¼Œå°è¯•ä»å…¨å±€é…ç½®åŠ è½½")
        try:
            from config import conf
            config = conf()
            if hasattr(config, "get"):
                OPENAI_API_KEY = config.get("open_ai_api_key")
                if OPENAI_API_KEY:
                    OPENAI_API_BASE = config.get("open_ai_api_base", OPENAI_API_BASE)
                    OPENAI_MODEL = config.get("open_ai_model", OPENAI_MODEL)
                    USE_OPENAI = True
                    logger.info(f"ä»å…¨å±€é…ç½®åŠ è½½OpenAIè®¾ç½®æˆåŠŸï¼APIåŸºç¡€URL: {OPENAI_API_BASE}, æ¨¡å‹: {OPENAI_MODEL}")
                else:
                    logger.warning("å…¨å±€é…ç½®ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        except Exception as e:
            logger.warning(f"åŠ è½½å…¨å±€OpenAIé…ç½®å¤±è´¥: {e}")
            
except Exception as e:
    logger.error(f"åŠ è½½é…ç½®æ—¶å‡ºé”™: {e}")
    logger.error(traceback.format_exc())

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
if USE_OPENAI:
    try:
        openai.api_key = OPENAI_API_KEY
        openai.api_base = OPENAI_API_BASE
        logger.info(f"OpenAIå®¢æˆ·ç«¯å·²åˆå§‹åŒ– - åŸºç¡€URL: {openai.api_base}, APIå¯†é’¥å‰8ä½: {OPENAI_API_KEY[:8]}...")
    except Exception as init_error:
        logger.error(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å¤±è´¥: {init_error}")
        logger.error(traceback.format_exc())
        USE_OPENAI = False

logger.info(f"OpenAIç­›é€‰åŠŸèƒ½çŠ¶æ€: {'å·²å¯ç”¨' if USE_OPENAI else 'æœªå¯ç”¨'}")

# é«˜é“APIåŸºç¡€URL
BASE_URL_HIGHSPEEDTICKET = "https://api.pearktrue.cn/api/highspeedticket"

@plugins.register(name="TicketQuery",
                  desc="æ™ºèƒ½ç¥¨åŠ¡æŸ¥è¯¢æ’ä»¶",
                  version="0.1",
                  author="sllt",
                  desire_priority=100)
class TicketQuery(Plugin):
    content = None
    ticket_info_list = []
    intermediate_ticket_info_list = []
    conversation_history = []
    last_interaction_time = None
    is_approximate_time = False
    approximate_time = None
    original_query = None
    
    # æ–°å¢å­—æ®µï¼Œç”¨äºä¿å­˜åŸå§‹æŸ¥è¯¢ç»“æœ
    original_data = []  # å­˜å‚¨åŸå§‹æŸ¥è¯¢ç»“æœ
    total_data = []     # å­˜å‚¨å½“å‰ç­›é€‰ç»“æœ
    current_page = 1

    def __init__(self):
        super().__init__()
        self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
        
        # åˆå§‹åŒ–åˆ†é¡µç›¸å…³å±æ€§
        self.current_page = 1
        self.page_size = 10  # æ¯é¡µæ˜¾ç¤º10æ¡
        self.last_query_params = None  # ä¿å­˜ä¸Šæ¬¡æŸ¥è¯¢å‚æ•°
        # åˆå§‹åŒ–è¿‘ä¼¼æ—¶é—´å±æ€§
        self.is_approximate_time = False
        self.approximate_time = None
        self.original_query = None
        
        # é‡æ–°åŠ è½½OpenAIé…ç½®ï¼Œç¡®ä¿é…ç½®æ­£ç¡®åŠ è½½
        self._load_openai_config()
        
        logger.info(f"[{__class__.__name__}] æ’ä»¶åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"OpenAIä½¿ç”¨çŠ¶æ€: {'å·²å¯ç”¨' if USE_OPENAI else 'æœªå¯ç”¨'}")
        if USE_OPENAI:
            logger.info(f"OpenAIé…ç½®ä¿¡æ¯: APIå¯†é’¥å‰8ä½={OPENAI_API_KEY[:8]}..., åŸºç¡€URL={OPENAI_API_BASE}, æ¨¡å‹={OPENAI_MODEL}")

    def _load_openai_config(self):
        """é‡æ–°åŠ è½½OpenAIé…ç½®"""
        global USE_OPENAI, OPENAI_API_KEY, OPENAI_API_BASE, OPENAI_MODEL, OPENAI_API_VERSION
        
        logger.info("====== é‡æ–°åŠ è½½OpenAIé…ç½® ======")
        try:
            # è·å–æ’ä»¶ç›®å½•è·¯å¾„
            plugin_dir = os.path.dirname(os.path.abspath(__file__))
            config_path = os.path.join(plugin_dir, "config.json")
            logger.info(f"å°è¯•ä» {config_path} åŠ è½½é…ç½®")
            
            if os.path.exists(config_path):
                logger.info(f"é…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹è¯»å–")
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        file_content = f.read()
                        logger.info(f"è¯»å–åˆ°é…ç½®æ–‡ä»¶å†…å®¹: {file_content}")
                        plugin_config = json.loads(file_content)
                    
                    logger.info(f"é…ç½®æ–‡ä»¶è§£æç»“æœ: {json.dumps(plugin_config, ensure_ascii=False)}")
                    
                    # æå–OpenAIé…ç½®
                    OPENAI_API_KEY = plugin_config.get("open_ai_api_key")
                    if OPENAI_API_KEY:
                        OPENAI_API_BASE = plugin_config.get("open_ai_api_base", OPENAI_API_BASE)
                        OPENAI_MODEL = plugin_config.get("open_ai_model", OPENAI_MODEL)
                        OPENAI_API_VERSION = plugin_config.get("open_ai_api_version", OPENAI_API_VERSION)
                        
                        # æ£€æŸ¥APIåŸºç¡€URLæ˜¯å¦å·²åŒ…å«APIç‰ˆæœ¬
                        if OPENAI_API_BASE.endswith(f"/{OPENAI_API_VERSION}"):
                            logger.info(f"APIåŸºç¡€URLå·²åŒ…å«ç‰ˆæœ¬ä¿¡æ¯: {OPENAI_API_BASE}")
                        else:
                            # å¦‚æœURLä¸æ˜¯ä»¥/ç»“å°¾ï¼Œæ·»åŠ /
                            if not OPENAI_API_BASE.endswith("/"):
                                OPENAI_API_BASE += "/"
                            # å†æ·»åŠ ç‰ˆæœ¬å·ï¼ˆä½†ä¸é‡å¤æ·»åŠ ï¼‰
                            if not OPENAI_API_BASE.endswith(f"{OPENAI_API_VERSION}/"):
                                OPENAI_API_BASE += f"{OPENAI_API_VERSION}"
                            logger.info(f"è°ƒæ•´åçš„APIåŸºç¡€URL: {OPENAI_API_BASE}")
                        
                        USE_OPENAI = True
                        
                        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                        openai.api_key = OPENAI_API_KEY
                        openai.api_base = OPENAI_API_BASE
                        
                        logger.info(f"OpenAIé…ç½®åŠ è½½æˆåŠŸ! APIå¯†é’¥å‰8ä½={OPENAI_API_KEY[:8]}..., åŸºç¡€URL={OPENAI_API_BASE}, æ¨¡å‹={OPENAI_MODEL}")
                        logger.info(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
                    else:
                        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
                        USE_OPENAI = False
                except Exception as e:
                    logger.error(f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                    logger.error(traceback.format_exc())
                    USE_OPENAI = False
            else:
                logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                USE_OPENAI = False
        except Exception as e:
            logger.error(f"åŠ è½½OpenAIé…ç½®æ—¶å‡ºé”™: {e}")
            logger.error(traceback.format_exc())
            USE_OPENAI = False
            
        logger.info(f"OpenAIé…ç½®åŠ è½½ç»“æœ: {'æˆåŠŸ' if USE_OPENAI else 'å¤±è´¥'}")
        return USE_OPENAI

    def get_help_text(self, **kwargs):
        help_text = """ã€ä½¿ç”¨è¯´æ˜ã€‘
1. åŸºç¡€æŸ¥è¯¢ï¼ˆæ˜¾ç¤ºå‰10æ¡ï¼‰ï¼š
   - ç¥¨ç§ å‡ºå‘åœ° ç»ˆç‚¹åœ° ï¼ˆä¾‹ï¼šé«˜é“ åŒ—äº¬ ä¸Šæµ·ï¼‰
   - ç¥¨ç§ å‡ºå‘åœ° ç»ˆç‚¹åœ° æ—¥æœŸ ï¼ˆä¾‹ï¼šé«˜é“ åŒ—äº¬ ä¸Šæµ· 2024-06-05ï¼‰
   - ç¥¨ç§ å‡ºå‘åœ° ç»ˆç‚¹åœ° æ—¥æœŸ æ—¶é—´ ï¼ˆä¾‹ï¼šé«˜é“ åŒ—äº¬ ä¸Šæµ· 2024-06-05 09:00ï¼‰

2. è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼š
   - "æŸ¥æ˜å¤©ä¸Šåˆä»åŒ—äº¬åˆ°ä¸Šæµ·çš„é«˜é“"
   - "ä»Šå¤©ä¸‹åˆ3ç‚¹çš„é«˜é“ä»åŒ—äº¬åˆ°ä¸Šæµ·"
   
3. åˆ†é¡µæ“ä½œï¼š
   - +ä¸‹ä¸€é¡µï¼šæŸ¥çœ‹åç»­ç»“æœ
   - +ä¸Šä¸€é¡µï¼šè¿”å›å‰é¡µç»“æœ

4. åç»­ç­›é€‰ï¼š
   - +æœ€ä¾¿å®œçš„äºŒç­‰åº§
   - +ä¸Šåˆå‡ºå‘çš„è½¦æ¬¡

5. ä¸­è½¬æŸ¥è¯¢ï¼š
   - ä¸­è½¬+é«˜é“ æˆéƒ½ ä¸Šæµ· 2024-06-05 09:00"""
        return help_text

    def on_handle_context(self, e_context: EventContext):
        if e_context['context'].type != ContextType.TEXT:
            return
            
        self.content = e_context["context"].content.strip()
        logger.info(f"æ”¶åˆ°æŸ¥è¯¢å†…å®¹ï¼š{self.content}")

        # å¤„ç†åˆ†é¡µå‘½ä»¤
        if self.content in ["+ä¸‹ä¸€é¡µ", "+ä¸Šä¸€é¡µ"]:
            self._handle_pagination(e_context)
            return

        # å¤„ç†åç»­ç­›é€‰é—®é¢˜
        if self.content.startswith("+"):
            logger.info("å¼€å§‹å¤„ç†åç»­ç­›é€‰é—®é¢˜")
            self._handle_followup_question(e_context)
            return

        # æ¸…ç†10åˆ†é’Ÿå‰çš„å†å²è®°å½•
        if self.last_interaction_time and datetime.now() - self.last_interaction_time > timedelta(minutes=10):
            self.conversation_history.clear()
            self.total_data = []
            self.current_page = 1
            logger.info("å·²æ¸…é™¤è¿‡æœŸå¯¹è¯å†å²")

        self.last_interaction_time = datetime.now()

        # å¤„ç†ä¸­è½¬æŸ¥è¯¢
        if self.content.startswith("ä¸­è½¬+") or "ä¸­è½¬" in self.content or "æ¢ä¹˜" in self.content:
            logger.info("æ£€æµ‹åˆ°ä¸­è½¬æŸ¥è¯¢è¯·æ±‚")
            self._handle_transfer_query(e_context)
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªç„¶è¯­è¨€æŸ¥è¯¢
        if any(keyword in self.content for keyword in ["é«˜é“", "åŠ¨è½¦", "æ™®é€š"]) and any(keyword in self.content for keyword in ["åˆ°", "å»", "è‡³"]):
            logger.info("æ£€æµ‹åˆ°è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œå¼€å§‹å¤„ç†")
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨OpenAIè¿›è¡Œå¤„ç†
            if USE_OPENAI:
                logger.info("====== ä½¿ç”¨OpenAIå¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢ ======")
                logger.info(f"APIå¯†é’¥çŠ¶æ€: {'å·²é…ç½®' if OPENAI_API_KEY else 'æœªé…ç½®'}")
                logger.info(f"APIåŸºç¡€URL: {OPENAI_API_BASE}")
                logger.info(f"ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
                
                # å°è¯•è°ƒç”¨OpenAIè§£æ
                parsed_query = self._ai_parse_query(self.content)
                if parsed_query:
                    logger.info(f"OpenAIæˆåŠŸè§£ææŸ¥è¯¢: {parsed_query}")
                    self.content = parsed_query
                    self._handle_main_query(e_context)
                    return
                else:
                    logger.warning("OpenAIè§£æå¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼è§£æ")
            else:
                logger.warning("OpenAIæœªé…ç½®ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ")
                
            # å¦‚æœOpenAIæœªé…ç½®æˆ–è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼è§£æ
            self._process_natural_language()
            # è‡ªç„¶è¯­è¨€å¤„ç†åç›´æ¥äº¤ç»™ä¸»æŸ¥è¯¢å¤„ç†
            self._handle_main_query(e_context)
            return

        # å¤„ç†ä¸»æŸ¥è¯¢
        if self.content.split()[0] in ["é«˜é“", "æ™®é€š", "åŠ¨è½¦"]:
            logger.info("å¼€å§‹å¤„ç†ä¸»æŸ¥è¯¢")
            self._handle_main_query(e_context)

    def _process_natural_language(self):
        """å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        try:
            logger.info(f"å¼€å§‹è§£æè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼š{self.content}")
            
            # 1. æå–è½¦å‹
            ticket_type = "é«˜é“" if "é«˜é“" in self.content else "åŠ¨è½¦" if "åŠ¨è½¦" in self.content else "æ™®é€š"
            
            # 2. æå–åŸå¸‚ - æ”¯æŒå¤šç§è¡¨è¾¾æ–¹å¼
            # åŒ¹é…æ¨¡å¼1ï¼šä»Aåˆ°B
            location_pattern1 = r"ä»([\u4e00-\u9fa5]+)åˆ°([\u4e00-\u9fa5]+)"
            # åŒ¹é…æ¨¡å¼2ï¼šAåˆ°B / Aè‡³B / Aå»B
            location_pattern2 = r"([\u4e00-\u9fa5]+)(?:åˆ°|è‡³|å»)([\u4e00-\u9fa5]+)"
            
            # å…ˆå¤„ç†æ—¥æœŸå’Œæ—¶é—´çŸ­è¯­
            time_keywords = ["ä»Šå¤©", "æ˜å¤©", "åå¤©", "ä¸‹åˆ", "ä¸Šåˆ", "æ™šä¸Š", "å‡Œæ™¨", "ä¸­åˆ", "æ—©ä¸Š"]
            cleaned_content = self.content
            for keyword in time_keywords:
                cleaned_content = cleaned_content.replace(keyword, " " + keyword + " ")
            
            logger.info(f"é¢„å¤„ç†åçš„æŸ¥è¯¢å†…å®¹ï¼š{cleaned_content}")
            
            # åœ¨é¢„å¤„ç†åçš„å†…å®¹ä¸­æŸ¥æ‰¾åŸå¸‚
            location_match = re.search(location_pattern1, cleaned_content)
            if not location_match:
                location_match = re.search(location_pattern2, cleaned_content)
                
            if not location_match:
                logger.warning("æœªæ‰¾åˆ°å‡ºå‘åœ°å’Œç›®çš„åœ°")
                return
                
            from_city = location_match.group(1).strip()
            to_city = location_match.group(2).strip()
            
            # æ¸…é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬å’Œæ—¶é—´è¯
            for keyword in time_keywords:
                from_city = from_city.replace(keyword, "").strip()
                to_city = to_city.replace(keyword, "").strip()
                
            # æ¸…é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬
            to_city = to_city.split("çš„")[0].strip() if "çš„" in to_city else to_city
            
            logger.info(f"è¯†åˆ«åˆ°åŸå¸‚ï¼š{from_city} -> {to_city}")
            
            # 3. å¤„ç†æ—¶é—´
            now = datetime.now()
            query_date = now.strftime("%Y-%m-%d")  # é»˜è®¤ä»Šå¤©
            query_time = None
            
            # å¤„ç†æ—¥æœŸ
            if "æ˜å¤©" in self.content:
                query_date = (now + timedelta(days=1)).strftime("%Y-%m-%d")
                logger.info(f"è¯†åˆ«åˆ°æ—¥æœŸï¼šæ˜å¤© ({query_date})")
            elif "åå¤©" in self.content:
                query_date = (now + timedelta(days=2)).strftime("%Y-%m-%d")
                logger.info(f"è¯†åˆ«åˆ°æ—¥æœŸï¼šåå¤© ({query_date})")
            else:
                logger.info(f"ä½¿ç”¨é»˜è®¤æ—¥æœŸï¼šä»Šå¤© ({query_date})")
                
            # å¤„ç†å…·ä½“æ—¶é—´
            time_pattern = r"(\d{1,2})(?:ç‚¹|æ—¶|:|ï¼š)(\d{0,2})(?:åˆ†|)|(\d{1,2})(?:ç‚¹|æ—¶)"
            time_match = re.search(time_pattern, self.content)
            
            if time_match:
                if time_match.group(3):  # åŒ¹é…äº†"3ç‚¹"è¿™ç§æ ¼å¼
                    hour = int(time_match.group(3))
                    minute = 0
                else:  # åŒ¹é…äº†"3:30"æˆ–"3ç‚¹30åˆ†"è¿™ç§æ ¼å¼
                    hour = int(time_match.group(1))
                    minute = int(time_match.group(2)) if time_match.group(2) else 0
                
                # å¤„ç†12å°æ—¶åˆ¶è½¬24å°æ—¶åˆ¶
                if "ä¸‹åˆ" in self.content or "æ™šä¸Š" in self.content:
                    if hour < 12:
                        hour += 12
                        
                query_time = f"{hour:02d}:{minute:02d}"
                logger.info(f"æå–åˆ°å…·ä½“æ—¶é—´ï¼š{query_time}")
                
                # å¤„ç†"å·¦å³"ã€"å‰å"ç­‰æ¨¡ç³Šè¡¨è¾¾ï¼Œè®¾ç½®æ—¶é—´çª—å£
                if any(word in self.content for word in ["å·¦å³", "å‰å", "é™„è¿‘"]):
                    # è¿™é‡Œæˆ‘ä»¬ä¸æ”¹å˜query_timeï¼Œä½†è®°å½•è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼æ—¶é—´
                    # åç»­å¤„ç†ä¸­ä¼šä½¿ç”¨ä¸€ä¸ªæ—¶é—´çª—å£ï¼Œæ¯”å¦‚Â±30åˆ†é’Ÿ
                    self.is_approximate_time = True
                    self.approximate_time = query_time
                    logger.info(f"æ£€æµ‹åˆ°æ¨¡ç³Šæ—¶é—´è¡¨è¾¾ï¼Œå°†ä½¿ç”¨{query_time}Â±30åˆ†é’Ÿçš„æ—¶é—´çª—å£")
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°å…·ä½“æ—¶é—´ï¼Œåˆ™å°è¯•æå–æ—¶é—´æ®µ
            if not query_time:
                if "ä¸Šåˆ" in self.content:
                    query_time = "09:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šä¸Šåˆï¼Œè®¾ç½®ä¸º09:00")
                elif "ä¸‹åˆ" in self.content and "æ™š" not in self.content:
                    query_time = "14:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šä¸‹åˆï¼Œè®¾ç½®ä¸º14:00")
                elif "æ™šä¸Š" in self.content or "å‚æ™š" in self.content:
                    query_time = "19:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šæ™šä¸Šï¼Œè®¾ç½®ä¸º19:00")
            
            # 4. æ„å»ºæŸ¥è¯¢å‚æ•°
            parts = [ticket_type, from_city, to_city]
            if query_date:
                parts.append(query_date)
            if query_time:
                parts.append(query_time)
                
            self.content = " ".join(parts)
            logger.info(f"è§£æç»“æœï¼š{self.content}")
            
            # 5. è®°å½•åŸå§‹æŸ¥è¯¢ï¼Œç”¨äºåç»­ç²¾ç¡®è¿‡æ»¤
            self.original_query = self.content
            if "å·¦å³" in self.content or "å‰å" in self.content or "é™„è¿‘" in self.content:
                self.is_approximate_time = True
                self.approximate_time = query_time
            else:
                self.is_approximate_time = False
                
        except Exception as e:
            logger.error(f"è‡ªç„¶è¯­è¨€è§£æå¤±è´¥ï¼š{e}")
            logger.error(traceback.format_exc())

    def _handle_main_query(self, e_context):
        """å¤„ç†ä¸»æŸ¥è¯¢è¯·æ±‚"""
        logger.info(f"å¤„ç†ä¸»æŸ¥è¯¢ï¼š{self.content}")
        parts = self.content.split()
        
        # æ£€æŸ¥å‚æ•°æ•°é‡
        if len(parts) < 3:
            self._send_error("å‚æ•°ä¸è¶³ï¼Œè¯·è‡³å°‘æä¾›è½¦å‹ã€å‡ºå‘åœ°å’Œç›®çš„åœ°", e_context)
            return

        try:
            # è§£æåŸºç¡€å‚æ•°
            ticket_type = parts[0]
            from_location = parts[1]
            to_location = parts[2]
            
            # è·å–å½“å‰æ—¶é—´
            now = datetime.now()
            query_date = now.strftime("%Y-%m-%d")
            query_time = None
            
            # å¤„ç†å¯é€‰å‚æ•°
            if len(parts) >= 4:
                if re.match(r"\d{4}-\d{2}-\d{2}", parts[3]):
                    query_date = parts[3]
                elif re.match(r"\d{1,2}:\d{2}", parts[3]):
                    query_time = parts[3]
                    
            if len(parts) >= 5:
                if re.match(r"\d{1,2}:\d{2}", parts[4]):
                    query_time = parts[4]

            # è®°å½•æŸ¥è¯¢å‚æ•°
            logger.info(f"æŸ¥è¯¢å‚æ•°ï¼šè½¦å‹={ticket_type}, å‡ºå‘={from_location}, åˆ°è¾¾={to_location}, "
                       f"æ—¥æœŸ={query_date}, æ—¶é—´={query_time or 'å…¨å¤©'}")

            # è·å–ç¥¨åŠ¡ä¿¡æ¯
            result = self.get_ticket_info(
                ticket_type, 
                from_location, 
                to_location,
                query_date,
                query_time
            )
            
            if result:
                # ä¿å­˜å®Œæ•´æ•°æ®ç”¨äºåˆ†é¡µ
                self.total_data = result
                self.last_query_params = (ticket_type, from_location, to_location, query_date, query_time)
                self.current_page = 1
                
                # æ˜¾ç¤ºç¬¬ä¸€é¡µç»“æœ
                reply = Reply()
                reply.type = ReplyType.TEXT
                reply.content = self._format_response(self._get_current_page())
            else:
                reply = Reply()
                reply.type = ReplyType.ERROR
                reply.content = "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡"
                
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS

        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            logger.error(traceback.format_exc())
            self._send_error("æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", e_context)

    def get_ticket_info(self, ticket_type, from_loc, to_loc, date, time=""):
        """è°ƒç”¨ç¥¨åŠ¡APIè·å–æ•°æ®"""
        logger.info(f"å¼€å§‹æŸ¥è¯¢è½¦ç¥¨ä¿¡æ¯ï¼š{ticket_type} {from_loc}->{to_loc} æ—¥æœŸï¼š{date} æ—¶é—´ï¼š{time}")
        
        # ä¿å­˜æ—¶é—´ä¿¡æ¯ç”¨äºåç»­è¿‡æ»¤
        if time:
            self.is_approximate_time = True
            self.approximate_time = time
            logger.info(f"è®¾ç½®è¿‘ä¼¼æ—¶é—´è¿‡æ»¤æ¡ä»¶ï¼š{time}Â±30åˆ†é’Ÿ")
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {
            "from": from_loc,
            "to": to_loc,
            "time": date,  # APIå‚æ•°ä¸ºtimeè€Œä¸æ˜¯date
            "type": ticket_type
        }
        
        # è¾“å‡ºå®Œæ•´è¯·æ±‚URL
        param_str = "&".join([f"{k}={v}" for k, v in params.items()])
        full_url = f"{BASE_URL_HIGHSPEEDTICKET}?{param_str}"
        logger.info(f"è¯·æ±‚URLï¼š{full_url}")
        
        try:
            resp = requests.get(BASE_URL_HIGHSPEEDTICKET, params=params, timeout=15)
            logger.info(f"APIå“åº”çŠ¶æ€ç ï¼š{resp.status_code}")
            logger.info(f"APIå“åº”å†…å®¹ï¼š{resp.text[:200]}...")  # åªè¾“å‡ºå‰200ä¸ªå­—ç¬¦é¿å…æ—¥å¿—è¿‡é•¿
            
            if resp.status_code != 200:
                logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{resp.status_code}")
                return None
                
            try:
                data = resp.json()
                logger.info(f"APIè¿”å›codeï¼š{data.get('code')}")
                logger.info(f"APIè¿”å›msgï¼š{data.get('msg')}")
                
                if data.get('code') == 200:
                    raw_data = data.get('data', [])
                    logger.info(f"è·å–åˆ°{len(raw_data)}æ¡åŸå§‹æ•°æ®")
                    
                    # å¤„ç†æ•°æ®å‰å…ˆè¾“å‡ºå‡ æ¡æ ·ä¾‹
                    if raw_data:
                        logger.info(f"æ•°æ®æ ·ä¾‹ï¼š{raw_data[0]}")
                    
                    filtered_trains = self._process_api_data(raw_data, ticket_type, time)
                    logger.info(f"ç­›é€‰åå‰©ä½™{len(filtered_trains)}æ¡æ•°æ®")
                    
                    if not filtered_trains:
                        logger.warning("ç­›é€‰åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡")
                    return filtered_trains
                else:
                    error_msg = data.get('msg', 'æœªçŸ¥é”™è¯¯')
                    logger.error(f"APIè¿”å›é”™è¯¯ï¼š{error_msg}")
                    return None
                    
            except json.JSONDecodeError as je:
                logger.error(f"JSONè§£æé”™è¯¯ï¼š{je}")
                logger.error(f"åŸå§‹å“åº”å†…å®¹ï¼š{resp.text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("APIè¯·æ±‚è¶…æ—¶")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"è¯·æ±‚å¼‚å¸¸ï¼š{e}")
            return None
        except Exception as e:
            logger.error(f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}")
            logger.error(f"é”™è¯¯è¯¦æƒ…ï¼š{traceback.format_exc()}")
            return None

    def _process_api_data(self, data, ticket_type, query_time):
        """å¤„ç†APIè¿”å›æ•°æ®"""
        logger.info(f"å¼€å§‹å¤„ç†APIæ•°æ®ï¼šè½¦å‹={ticket_type}, æŸ¥è¯¢æ—¶é—´={query_time}")
        logger.info(f"æ”¶åˆ°{len(data)}æ¡æ•°æ®å¾…å¤„ç†")
        
        # è®°å½•æ—¶é—´è¿‡æ»¤çŠ¶æ€
        if self.is_approximate_time:
            logger.info(f"å¯ç”¨è¿‘ä¼¼æ—¶é—´è¿‡æ»¤ï¼š{self.approximate_time}Â±30åˆ†é’Ÿ")
        elif query_time:
            logger.info(f"å¯ç”¨ç²¾ç¡®æ—¶é—´è¿‡æ»¤ï¼š{query_time}ä¹‹åçš„è½¦æ¬¡")
        else:
            logger.info("æœªæŒ‡å®šæ—¶é—´è¿‡æ»¤æ¡ä»¶ï¼Œå°†è¿”å›å…¨å¤©è½¦æ¬¡")
        
        filtered = []
        for item in data:
            try:
                # è®°å½•æ¯æ¡æ•°æ®çš„å¤„ç†
                train_number = item.get('trainumber', 'unknown')
                train_type = item.get('traintype', 'unknown')
                depart_time = item.get('departtime', 'unknown')
                
                logger.info(f"å¤„ç†è½¦æ¬¡ï¼š{train_number} ç±»å‹ï¼š{train_type} å‘è½¦ï¼š{depart_time}")
                
                # 1. è½¦å‹ç­›é€‰
                if train_type != ticket_type:
                    logger.debug(f"è½¦æ¬¡{train_number}ç±»å‹ä¸åŒ¹é…ï¼Œè·³è¿‡")
                    continue
                    
                # 2. æ—¶é—´ç­›é€‰
                # å¦‚æœæ˜¯è¿‘ä¼¼æ—¶é—´æŸ¥è¯¢ï¼ˆä¾‹å¦‚"10ç‚¹å·¦å³"ï¼‰ï¼Œä½¿ç”¨æ—¶é—´çª—å£
                if self.is_approximate_time and self.approximate_time:
                    try:
                        # è§£æè¿‘ä¼¼æ—¶é—´å’Œå‘è½¦æ—¶é—´
                        approx_time_obj = datetime.strptime(self.approximate_time, "%H:%M").time()
                        depart_time_obj = datetime.strptime(depart_time, "%H:%M").time()
                        
                        # è®¡ç®—æ—¶é—´å·®ï¼ˆåˆ†é’Ÿï¼‰
                        approx_minutes = approx_time_obj.hour * 60 + approx_time_obj.minute
                        depart_minutes = depart_time_obj.hour * 60 + depart_time_obj.minute
                        time_diff = abs(approx_minutes - depart_minutes)
                        
                        # ä½¿ç”¨30åˆ†é’Ÿçš„æ—¶é—´çª—å£
                        if time_diff > 30:
                            logger.info(f"è½¦æ¬¡{train_number}å‘è½¦æ—¶é—´{depart_time}ä¸è¿‘ä¼¼æ—¶é—´{self.approximate_time}ç›¸å·®{time_diff}åˆ†é’Ÿï¼Œè¶…å‡º30åˆ†é’Ÿçª—å£ï¼Œè·³è¿‡")
                            continue
                        else:
                            logger.info(f"âœ“ è½¦æ¬¡{train_number}å‘è½¦æ—¶é—´{depart_time}åœ¨è¿‘ä¼¼æ—¶é—´{self.approximate_time}çš„30åˆ†é’Ÿçª—å£å†…")
                    except ValueError as e:
                        logger.warning(f"è¿‘ä¼¼æ—¶é—´æ ¼å¼è§£æé”™è¯¯: {e}")
                        
                # å¸¸è§„æ—¶é—´ç­›é€‰
                elif query_time:
                    try:
                        query_time_obj = datetime.strptime(query_time, "%H:%M").time()
                        depart_time_obj = datetime.strptime(depart_time, "%H:%M").time()
                        
                        # è®¡ç®—æ—¶é—´å·®ï¼ˆåˆ†é’Ÿï¼‰
                        query_minutes = query_time_obj.hour * 60 + query_time_obj.minute
                        depart_minutes = depart_time_obj.hour * 60 + depart_time_obj.minute
                        time_diff = depart_minutes - query_minutes
                        
                        if time_diff < -30:  # å‘è½¦æ—¶é—´æ—©äºæŸ¥è¯¢æ—¶é—´30åˆ†é’Ÿä»¥ä¸Š
                            logger.info(f"è½¦æ¬¡{train_number}å‘è½¦æ—¶é—´{depart_time}æ—©äºæŸ¥è¯¢æ—¶é—´{query_time}è¶…è¿‡30åˆ†é’Ÿï¼Œè·³è¿‡")
                            continue
                        else:
                            logger.info(f"âœ“ è½¦æ¬¡{train_number}å‘è½¦æ—¶é—´{depart_time}æ¥è¿‘æˆ–æ™šäºæŸ¥è¯¢æ—¶é—´{query_time}")
                    except ValueError as e:
                        logger.warning(f"æ—¶é—´æ ¼å¼è§£æé”™è¯¯: {e}")
                        continue
                        
                # 3. æ·»åŠ æœ‰æ•ˆæ•°æ®
                filtered.append(item)
                logger.info(f"âœ… æ·»åŠ ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡ï¼š{train_number}, å‘è½¦æ—¶é—´ï¼š{depart_time}, åˆ°è¾¾æ—¶é—´ï¼š{item.get('arrivetime', 'unknown')}")
                          
            except KeyError as ke:
                logger.warning(f"æ•°æ®æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘å¿…è¦å­—æ®µï¼š{ke}")
                continue
            except Exception as e:
                logger.warning(f"å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                continue

        # æŒ‰å‘è½¦æ—¶é—´æ’åº
        filtered.sort(key=lambda x: x['departtime'])
        logger.info(f"ç­›é€‰å®Œæˆï¼Œå…±æœ‰{len(filtered)}æ¡ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡")
        
        # è¾“å‡ºç­›é€‰åçš„ç¬¬ä¸€æ¡æ•°æ®ä½œä¸ºæ ·ä¾‹
        if filtered:
            logger.info(f"ç­›é€‰åæ•°æ®æ ·ä¾‹ï¼š{filtered[0]}")
        
        return filtered
        
    def _handle_pagination(self, e_context):
        """å¤„ç†åˆ†é¡µè¯·æ±‚"""
        if not self.total_data:
            self._send_error("è¯·å…ˆè¿›è¡Œè½¦æ¬¡æŸ¥è¯¢", e_context)
            return

        # è®¡ç®—æ€»é¡µæ•°
        total_pages = (len(self.total_data) + self.page_size - 1) // self.page_size

        if self.content == "+ä¸‹ä¸€é¡µ":
            if self.current_page < total_pages:
                self.current_page += 1
            else:
                self._send_error("å·²ç»æ˜¯æœ€åä¸€é¡µäº†", e_context)
                return
        elif self.content == "+ä¸Šä¸€é¡µ":
            if self.current_page > 1:
                self.current_page -= 1
            else:
                self._send_error("å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†", e_context)
                return

        # è·å–å½“å‰é¡µæ•°æ®
        page_data = self._get_current_page()
        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = self._format_response(page_data)
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS

    def _get_current_page(self):
        """è·å–å½“å‰é¡µæ•°æ®"""
        start = (self.current_page - 1) * self.page_size
        end = start + self.page_size
        return self.total_data[start:end]
        
    def _format_response(self, page_data):
        if not page_data:
            return "æ²¡æœ‰æ›´å¤šè½¦æ¬¡ä¿¡æ¯"

        # é™åˆ¶æœ€å¤§æ˜¾ç¤ºç»“æœï¼Œé¿å…æ¶ˆæ¯è¿‡é•¿
        if len(page_data) > 20:
            logger.warning(f"ç»“æœè¿‡å¤š({len(page_data)}æ¡)ï¼Œåªæ˜¾ç¤ºå‰20æ¡")
            page_data = page_data[:20]

        result = []
        global_index = (self.current_page - 1) * self.page_size + 1
        for idx, item in enumerate(page_data, global_index):
            info = f"{idx}. ã€{item.get('trainumber', 'æœªçŸ¥è½¦æ¬¡')}ã€‘{item.get('traintype', 'æœªçŸ¥ç±»å‹')}\n"
            info += f"   ğŸš©å‡ºå‘ç«™ï¼š{item.get('departstation', 'æœªçŸ¥')} â” åˆ°è¾¾ç«™ï¼š{item.get('arrivestation', 'æœªçŸ¥')}\n"
            info += f"   â°æ—¶é—´ï¼š{item.get('departtime', 'æœªçŸ¥')} - {item.get('arrivetime', 'æœªçŸ¥')}ï¼ˆå†æ—¶ï¼š{item.get('runtime', 'æœªçŸ¥')}\n"
            
            # å¤„ç†ç¥¨ä»·ä¿¡æ¯
            seats = item.get('ticket_info', [])
            if seats:
                seat_info = "   ğŸ’ºå¸­ä½ï¼š"
                seat_info += " | ".join([
                    f"{s.get('seatname', 'æœªçŸ¥')}ï¼šÂ¥{s.get('seatprice', 'æœªçŸ¥')}ï¼ˆä½™{s.get('seatinventory', 0)}å¼ ï¼‰"
                    for s in seats
                ])
                info += seat_info + "\n"
            else:
                info += "   âš ï¸æš‚æ— ä½™ç¥¨ä¿¡æ¯\n"
            
            result.append(info)
            
        total_pages = (len(self.total_data) + self.page_size - 1) // self.page_size
        footer = f"\nğŸ“„ç¬¬ {self.current_page}/{total_pages} é¡µ"
        footer += f"\nğŸ”å…±æ‰¾åˆ° {len(self.total_data)} æ¡ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡"
        footer += "\nğŸ”å‘é€ã€+ä¸‹ä¸€é¡µã€‘æŸ¥çœ‹åç»­ç»“æœ" if self.current_page < total_pages else ""
        footer += "\nğŸ¯å‘é€ã€+ç­›é€‰æ¡ä»¶ã€‘è¿›è¡Œç²¾ç¡®ç­›é€‰ï¼ˆå¦‚ï¼š+äºŒç­‰åº§ä½äº500å…ƒï¼‰"
        return "\n".join(result) + footer

    def _handle_followup_question(self, e_context):
        """å¤„ç†åç»­ç­›é€‰é—®é¢˜"""
        content = self.content[1:]  # å»æ‰å¼€å¤´çš„"+"
        logger.info(f"æ”¶åˆ°ç­›é€‰é—®é¢˜ï¼š+{content}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æŸ¥è¯¢ç»“æœ
        if not self.original_data:
            self._send_error("è¯·å…ˆè¿›è¡Œè½¦æ¬¡æŸ¥è¯¢", e_context)
            return
            
        # åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨OpenAIè¿›è¡Œæ™ºèƒ½ç­›é€‰
        if USE_OPENAI:
            logger.info("====== ä½¿ç”¨OpenAIè¿›è¡Œæ™ºèƒ½ç­›é€‰ ======")
            logger.info(f"APIå¯†é’¥å‰8ä½: {OPENAI_API_KEY[:8] if OPENAI_API_KEY else 'æœªé…ç½®'}")
            logger.info(f"APIåŸºç¡€URL: {OPENAI_API_BASE}")
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
            
            # åˆ¤æ–­æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­è½¬æŸ¥è¯¢ç»“æœ
            if hasattr(self, 'is_transfer_query') and self.is_transfer_query:
                logger.info("æ£€æµ‹åˆ°æ­£åœ¨å¤„ç†ä¸­è½¬æŸ¥è¯¢ç»“æœï¼Œä½¿ç”¨ä¸­è½¬ç­›é€‰æµç¨‹")
                filtered_data = self._ai_filter_transfer(content)
            else:
                logger.info("ä½¿ç”¨æ™®é€šæŸ¥è¯¢ç­›é€‰æµç¨‹")
                filtered_data = self._ai_filter(content)
        else:
            logger.info("OpenAIæœªé…ç½®ï¼Œä½¿ç”¨æœ¬åœ°ç­›é€‰é€»è¾‘")
            
            # åˆ¤æ–­æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­è½¬æŸ¥è¯¢ç»“æœ
            if hasattr(self, 'is_transfer_query') and self.is_transfer_query:
                logger.info("æ£€æµ‹åˆ°æ­£åœ¨å¤„ç†ä¸­è½¬æŸ¥è¯¢ç»“æœï¼Œä½¿ç”¨ä¸­è½¬ç­›é€‰æµç¨‹")
                filtered_data = self._manual_filter_transfer(content)
            else:
                logger.info("ä½¿ç”¨æ™®é€šæŸ¥è¯¢ç­›é€‰æµç¨‹")
                filtered_data = self._manual_filter(content)
        
        # æ›´æ–°ç°æœ‰æ•°æ® - åªæ›´æ–°total_dataï¼Œä¿ç•™original_data
        if filtered_data is not None:
            if len(filtered_data) > 0:
                self.total_data = filtered_data
                self.current_page = 1
                
                # æ ¼å¼åŒ–å“åº”
                if hasattr(self, 'is_transfer_query') and self.is_transfer_query:
                    reply_content = self._format_transfer_response(filtered_data[:20])  # é™åˆ¶æ˜¾ç¤ºæ¡æ•°
                else:
                    page_data = self._get_current_page()
                    reply_content = self._format_response(page_data)
                
                reply = Reply()
                reply.type = ReplyType.TEXT
                reply.content = reply_content
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
            else:
                self._send_error("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡", e_context)
        else:
            self._send_error("ç­›é€‰å¤±è´¥ï¼Œè¯·é‡è¯•", e_context)

    def _ai_filter_transfer(self, question):
        """é’ˆå¯¹ä¸­è½¬æŸ¥è¯¢ç»“æœçš„AIç­›é€‰"""
        logger.info(f"ä½¿ç”¨AIç­›é€‰ä¸­è½¬æŸ¥è¯¢ç»“æœ: {question}")
        
        if not USE_OPENAI or not OPENAI_API_KEY:
            logger.warning("OpenAIé…ç½®æ— æ•ˆï¼Œå›é€€åˆ°æ‰‹åŠ¨ç­›é€‰")
            return self._manual_filter_transfer(question)
            
        try:
            # é…ç½®OpenAI
            logger.info(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯...")
            logger.info(f"APIå¯†é’¥: {OPENAI_API_KEY[:8]}...")
            logger.info(f"APIåŸºç¡€URL: {OPENAI_API_BASE}")
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
            
            # å¼ºåˆ¶é‡æ–°é…ç½®OpenAI
            openai.api_key = OPENAI_API_KEY
            openai.api_base = OPENAI_API_BASE
            
            # å‡†å¤‡æ•°æ®ï¼Œå§‹ç»ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼Œé™åˆ¶æ•°é‡é˜²æ­¢è¶…å‡ºAPIé™åˆ¶
            max_data_items = min(len(self.original_data), 20)
            sample_data = self.original_data[:max_data_items]
            
            # æ„å»ºç®€åŒ–çš„æ ·æœ¬æ•°æ®ä»¥é€‚åº”tokené™åˆ¶
            simplified_samples = []
            for route in sample_data:
                simplified = {
                    "transfer_station": route.get("transfer_station"),
                    "total_price": route.get("total_price"),
                    "total_runtime": route.get("total_runtime"),
                    "first_leg": {
                        "trainumber": route.get("first_leg", {}).get("trainumber"),
                        "traintype": route.get("first_leg", {}).get("traintype"),
                        "departtime": route.get("first_leg", {}).get("departtime"),
                        "arrivetime": route.get("first_leg", {}).get("arrivetime"),
                        "departstation": route.get("first_leg", {}).get("departstation"),
                        "ticket_info": [
                            {
                                "seatname": seat.get("seatname"),
                                "seatprice": seat.get("seatprice"),
                                "seatinventory": seat.get("seatinventory")
                            } for seat in route.get("first_leg", {}).get("ticket_info", [])[:2]  # åªåŒ…å«å‰ä¸¤ç§åº§ä½ç±»å‹
                        ]
                    },
                    "second_leg": {
                        "trainumber": route.get("second_leg", {}).get("trainumber"),
                        "traintype": route.get("second_leg", {}).get("traintype"),
                        "departtime": route.get("second_leg", {}).get("departtime"),
                        "arrivetime": route.get("second_leg", {}).get("arrivetime"),
                        "arrivestation": route.get("second_leg", {}).get("arrivestation"),
                        "ticket_info": [
                            {
                                "seatname": seat.get("seatname"),
                                "seatprice": seat.get("seatprice"),
                                "seatinventory": seat.get("seatinventory")
                            } for seat in route.get("second_leg", {}).get("ticket_info", [])[:2]  # åªåŒ…å«å‰ä¸¤ç§åº§ä½ç±»å‹
                        ]
                    },
                    "transfer_time": route.get("transfer_time"),
                    "index": sample_data.index(route)  # æ·»åŠ ç´¢å¼•ä»¥ä¾¿åç»­æŸ¥æ‰¾
                }
                simplified_samples.append(simplified)
            
            sample_json = json.dumps(simplified_samples, ensure_ascii=False)
            logger.info(f"å·²å‡†å¤‡{len(simplified_samples)}/{len(self.original_data)}æ¡ä¸­è½¬æ•°æ®ç”¨äºAIåˆ†æ")
            
            # æ„å»ºæç¤º
            prompt = f"""
            æˆ‘éœ€è¦æŒ‰ä»¥ä¸‹æ¡ä»¶ç­›é€‰ä¸­è½¬åˆ—è½¦æ–¹æ¡ˆ: "{question}"
            
            ä¸­è½¬æ–¹æ¡ˆæ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š
            {sample_json}
            
            è¯·åˆ†æç­›é€‰æ¡ä»¶ï¼Œå¹¶è¿”å›ç¬¦åˆæ¡ä»¶çš„ä¸­è½¬æ–¹æ¡ˆã€‚è¿”å›æ ¼å¼ä¸ºJSONï¼š
            {{
                "analysis": "å¯¹ç­›é€‰æ¡ä»¶çš„ç†è§£å’Œåˆ†æ...",
                "matched_routes": [0, 2, 5]  // åŒ¹é…çš„æ–¹æ¡ˆåœ¨åŸæ•°ç»„ä¸­çš„ç´¢å¼•
            }}
            
            å¦‚æœç­›é€‰æ¡ä»¶æ¶‰åŠæ€»ä»·æ ¼ï¼Œè¯·æŸ¥çœ‹total_priceå­—æ®µï¼›
            å¦‚æœæ¶‰åŠæ€»æ—¶é—´ï¼Œè¯·æŸ¥çœ‹total_runtimeå­—æ®µï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼›
            å¦‚æœæ¶‰åŠè½¦æ¬¡å·ï¼Œè¯·æŸ¥çœ‹first_legå’Œsecond_legä¸­çš„trainumberå­—æ®µï¼›
            å¦‚æœæ¶‰åŠåº§ä½ç±»å‹å’Œä»·æ ¼ï¼Œè¯·æŸ¥çœ‹ticket_infoæ•°ç»„ã€‚
            å¦‚æœæ¶‰åŠä¸­è½¬ç«™ï¼Œè¯·æŸ¥çœ‹transfer_stationå­—æ®µ,åªæœ‰å®Œå…¨åŒ¹é…æ‰ç®—ç¬¦åˆæ¡ä»¶ã€‚
            
            ä»…è¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚
            """
            
            # è°ƒç”¨OpenAI API
            logger.info(f"æ­£åœ¨è°ƒç”¨OpenAI API - ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
            
            try:
                # å°è¯•å¤šç§APIè°ƒç”¨æ–¹å¼
                result_text = ""
                
                try:
                    # æ–°ç‰ˆAPI
                    response = openai.ChatCompletion.create(
                        model=OPENAI_MODEL,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                        max_tokens=1000
                    )
                    result_text = response.choices[0].message.content.strip()
                except AttributeError:
                    try:
                        # æœ€æ–°å®¢æˆ·ç«¯æ ¼å¼
                        response = openai.chat.completions.create(
                            model=OPENAI_MODEL,
                            messages=[{"role": "user", "content": prompt}],
                            temperature=0.3,
                            max_tokens=1000
                        )
                        result_text = response.choices[0].message.content.strip()
                    except Exception as latest_error:
                        # æ—§ç‰ˆAPI
                        response = openai.Completion.create(
                            model=OPENAI_MODEL,
                            prompt=prompt,
                            temperature=0.3,
                            max_tokens=1000
                        )
                        result_text = response.choices[0].text.strip()
            
                # å¤„ç†APIå“åº”
                if not result_text:
                    logger.warning("OpenAIè¿”å›äº†ç©ºå“åº”")
                    return self._manual_filter_transfer(question)
                    
                logger.info(f"OpenAIè¿”å›å“åº”é•¿åº¦: {len(result_text)} å­—ç¬¦")
                
                # å»é™¤markdownæ ¼å¼
                if result_text.startswith("```"):
                    pattern = r"```(?:json)?\s*([\s\S]*?)```"
                    match = re.search(pattern, result_text)
                    if match:
                        result_text = match.group(1).strip()
                
                # è§£æJSONå“åº”
                result_json = json.loads(result_text)
                indices = result_json.get("matched_routes", [])
                logger.info(f"AIåˆ†æ: {result_json.get('analysis', 'æ— åˆ†æ')[:100]}...")
                logger.info(f"åŒ¹é…ç´¢å¼•: {indices}")
                
                # æ ¹æ®ç´¢å¼•ç­›é€‰ - ä½¿ç”¨å…¨éƒ¨åŸå§‹æ•°æ®
                if indices:
                    # éœ€è¦ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                    valid_indices = [i for i in indices if 0 <= i < len(self.original_data)]
                    filtered = [self.original_data[i] for i in valid_indices]
                    logger.info(f"ç­›é€‰ç»“æœ: ä¿ç•™{len(filtered)}/{len(self.original_data)}æ¡ä¸­è½¬æ–¹æ¡ˆ")
                    
                    # æ ¹æ®ç­›é€‰æ¡ä»¶ç¡®å®šæ’åºæ–¹å¼
                    if any(word in question for word in ["æœ€ä¾¿å®œ", "ä»·æ ¼æœ€ä½", "ä¾¿å®œ", "ä½ä»·", "æœ€ä½", "æ€»ç¥¨ä»·"]):
                        logger.info("æ£€æµ‹åˆ°ä»·æ ¼ç›¸å…³ç­›é€‰æ¡ä»¶ï¼Œå¯¹ç»“æœæŒ‰ä»·æ ¼æ’åº")
                        filtered.sort(key=lambda x: float(x.get('total_price', float('inf'))))
                    elif any(word in question for word in ["æœ€å¿«", "æ—¶é—´æœ€çŸ­", "è€—æ—¶æœ€å°‘", "æœ€çŸ­", "æ€»æ—¶é•¿"]):
                        logger.info("æ£€æµ‹åˆ°æ—¶é—´ç›¸å…³ç­›é€‰æ¡ä»¶ï¼Œå¯¹ç»“æœæŒ‰æ—¶é—´æ’åº")
                        filtered.sort(key=lambda x: int(x.get('total_runtime', float('inf'))))
                        
                    # å¦‚æœæ˜¯è¦æ±‚æœ€ä¾¿å®œ/æœ€å¿«çš„ä¸€ä¸ªï¼Œåªè¿”å›ç¬¬ä¸€ä¸ªç»“æœ
                    if "æœ€" in question and filtered:
                        if any(word in question for word in ["æœ€ä¾¿å®œ", "ä»·æ ¼æœ€ä½", "æœ€ä½", "æ€»ç¥¨ä»·æœ€ä½"]):
                            logger.info(f"æ ¹æ®'æœ€ä¾¿å®œ'æ¡ä»¶ï¼Œåªè¿”å›ä»·æ ¼æœ€ä½çš„æ–¹æ¡ˆ: {filtered[0].get('total_price')}å…ƒ")
                            return [filtered[0]]
                        elif any(word in question for word in ["æœ€å¿«", "æ—¶é—´æœ€çŸ­", "è€—æ—¶æœ€å°‘", "æ€»æ—¶é•¿æœ€çŸ­"]):
                            logger.info(f"æ ¹æ®'æœ€å¿«'æ¡ä»¶ï¼Œåªè¿”å›æ—¶é—´æœ€çŸ­çš„æ–¹æ¡ˆ: {filtered[0].get('total_runtime')}åˆ†é’Ÿ")
                            return [filtered[0]]
                    
                    return filtered
                else:
                    # å¦‚æœAIæ— æ³•æ‰¾åˆ°åŒ¹é…çš„ï¼Œå›é€€åˆ°æ‰‹åŠ¨ç­›é€‰
                    logger.warning("AIæœªæ‰¾åˆ°åŒ¹é…çš„ä¸­è½¬æ–¹æ¡ˆï¼Œå°è¯•æ‰‹åŠ¨ç­›é€‰")
                    return self._manual_filter_transfer(question)
                    
            except Exception as api_error:
                logger.error(f"APIè°ƒç”¨æˆ–è§£æå¤±è´¥: {api_error}")
                logger.error(traceback.format_exc())
                return self._manual_filter_transfer(question)
                
        except Exception as e:
            logger.error(f"AIç­›é€‰ä¸­è½¬æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self._manual_filter_transfer(question)

    def _manual_filter_transfer(self, question):
        """é’ˆå¯¹ä¸­è½¬æŸ¥è¯¢ç»“æœçš„æ‰‹åŠ¨ç­›é€‰"""
        logger.info(f"æ‰‹åŠ¨ç­›é€‰ä¸­è½¬æŸ¥è¯¢ç»“æœ: {question}")
        
        # å§‹ç»ˆä½¿ç”¨åŸå§‹æ•°æ®ä½œä¸ºç­›é€‰åŸºç¡€
        data_to_filter = self.original_data
        logger.info(f"åŸºäº{len(data_to_filter)}æ¡åŸå§‹æ•°æ®è¿›è¡Œç­›é€‰")
        
        # ç­›é€‰é€»è¾‘ - ä¸­è½¬ç«™ç›¸å…³
        if any(station in question for station in MAJOR_STATIONS):
            logger.info("æ£€æµ‹åˆ°ä¸­è½¬ç«™ç›¸å…³ç­›é€‰æ¡ä»¶")
            
            # æå–æŒ‡å®šçš„ä¸­è½¬ç«™
            specified_station = None
            for station in MAJOR_STATIONS:
                if station in question:
                    specified_station = station
                    logger.info(f"è¯†åˆ«åˆ°ç­›é€‰æ¡ä»¶ä¸­çš„ä¸­è½¬ç«™: {station}")
                    break
                    
            if specified_station:
                logger.info(f"ç­›é€‰ä¸­è½¬ç«™ä¸º{specified_station}çš„æ–¹æ¡ˆ")
                filtered = []
                for route in data_to_filter:
                    station = route.get('transfer_station')
                    logger.info(f"æ£€æŸ¥è·¯çº¿ä¸­è½¬ç«™: {station}")
                    if station == specified_station:
                        filtered.append(route)
                
                logger.info(f"æ‰¾åˆ°{len(filtered)}ä¸ªç»è¿‡{specified_station}çš„ä¸­è½¬æ–¹æ¡ˆ")
                return filtered
        
        # ç­›é€‰é€»è¾‘ - ä»·æ ¼ç›¸å…³
        elif any(word in question for word in ["æœ€ä¾¿å®œ", "ä»·æ ¼æœ€ä½", "ä¾¿å®œ", "ä½ä»·", "æœ€ä½", "æ€»ç¥¨ä»·"]):
            logger.info("æ£€æµ‹åˆ°ä»·æ ¼ç›¸å…³ç­›é€‰æ¡ä»¶")
            
            # æŒ‰æ€»ä»·æ’åº
            sorted_routes = sorted(data_to_filter, key=lambda x: float(x.get('total_price', float('inf'))))
            logger.info(f"æŒ‰æ€»ä»·æ’åºå®Œæˆï¼Œå‰3ä¸ªæ–¹æ¡ˆçš„ä»·æ ¼: " + 
                       ", ".join([f"{route.get('total_price', 'N/A')}å…ƒ" for route in sorted_routes[:3]]))
            
            # æ˜¯å¦åªè¿”å›æœ€ä½ä»·
            if any(word in question for word in ["æœ€ä¾¿å®œ", "ä»·æ ¼æœ€ä½", "æœ€ä½", "æ€»ç¥¨ä»·æœ€ä½"]):
                if sorted_routes:
                    logger.info(f"æ‰¾åˆ°æœ€ä¾¿å®œçš„ä¸­è½¬æ–¹æ¡ˆï¼Œæ€»ä»·: {sorted_routes[0].get('total_price')}å…ƒ")
                    return [sorted_routes[0]]
                else:
                    return []
            else:
                logger.info(f"æŒ‰æ€»ä»·æ’åºï¼Œæ‰¾åˆ°{len(sorted_routes)}ä¸ªæ–¹æ¡ˆ")
                return sorted_routes
                
        # ç­›é€‰é€»è¾‘ - æ—¶é—´ç›¸å…³
        elif any(word in question for word in ["æœ€å¿«", "æ—¶é—´æœ€çŸ­", "è€—æ—¶æœ€å°‘", "æœ€çŸ­", "æ€»æ—¶é•¿"]):
            logger.info("æ£€æµ‹åˆ°æ—¶é—´ç›¸å…³ç­›é€‰æ¡ä»¶")
            
            # æŒ‰æ€»æ—¶é—´æ’åº
            sorted_routes = sorted(data_to_filter, key=lambda x: int(x.get('total_runtime', float('inf'))))
            logger.info(f"æŒ‰æ€»æ—¶é•¿æ’åºå®Œæˆï¼Œå‰3ä¸ªæ–¹æ¡ˆçš„æ—¶é•¿(åˆ†é’Ÿ): " + 
                       ", ".join([f"{route.get('total_runtime', 'N/A')}" for route in sorted_routes[:3]]))
            
            # æ˜¯å¦åªè¿”å›æœ€å¿«çš„
            if any(word in question for word in ["æœ€å¿«", "æ—¶é—´æœ€çŸ­", "è€—æ—¶æœ€å°‘", "æ€»æ—¶é•¿æœ€çŸ­"]):
                if sorted_routes:
                    total_minutes = sorted_routes[0].get('total_runtime', 0)
                    hours = total_minutes // 60
                    mins = total_minutes % 60
                    logger.info(f"æ‰¾åˆ°æœ€å¿«çš„ä¸­è½¬æ–¹æ¡ˆï¼Œæ€»æ—¶é•¿: {hours}å°æ—¶{mins}åˆ†é’Ÿ")
                    return [sorted_routes[0]]
                else:
                    return []
            else:
                logger.info(f"æŒ‰æ€»æ—¶é•¿æ’åºï¼Œæ‰¾åˆ°{len(sorted_routes)}ä¸ªæ–¹æ¡ˆ")
                return sorted_routes
                
        # ç­›é€‰é€»è¾‘ - æ¢ä¹˜æ—¶é—´ç›¸å…³
        elif any(word in question for word in ["æ¢ä¹˜æ—¶é—´", "ä¸­è½¬æ—¶é—´", "ç­‰å¾…æ—¶é—´"]):
            logger.info("æ£€æµ‹åˆ°æ¢ä¹˜æ—¶é—´ç›¸å…³ç­›é€‰æ¡ä»¶")
            
            # æ˜¯å¦è¦æ±‚æœ€çŸ­æ¢ä¹˜æ—¶é—´
            if any(word in question for word in ["æœ€çŸ­", "æœ€å°‘"]):
                sorted_routes = sorted(data_to_filter, key=lambda x: int(x.get('transfer_time', float('inf'))))
                if sorted_routes:
                    logger.info(f"æ‰¾åˆ°æ¢ä¹˜æ—¶é—´æœ€çŸ­çš„æ–¹æ¡ˆ: {sorted_routes[0].get('transfer_time')}åˆ†é’Ÿ")
                    return [sorted_routes[0]]
                
            # æ˜¯å¦è¦æ±‚æœ€é•¿æ¢ä¹˜æ—¶é—´ï¼ˆå¯èƒ½æ˜¯ä¸ºäº†åœ¨ä¸­è½¬ç«™æ¸¸ç©ï¼‰
            elif any(word in question for word in ["æœ€é•¿", "æœ€å¤š"]):
                sorted_routes = sorted(data_to_filter, key=lambda x: int(x.get('transfer_time', 0)), reverse=True)
                if sorted_routes:
                    logger.info(f"æ‰¾åˆ°æ¢ä¹˜æ—¶é—´æœ€é•¿çš„æ–¹æ¡ˆ: {sorted_routes[0].get('transfer_time')}åˆ†é’Ÿ")
                    return [sorted_routes[0]]
        
        # ç­›é€‰é€»è¾‘ - è½¦æ¬¡å·ç›¸å…³
        elif "è½¦æ¬¡" in question or "ç­æ¬¡" in question:
            for route in data_to_filter:
                first_train = route.get('first_leg', {}).get('trainumber', '')
                second_train = route.get('second_leg', {}).get('trainumber', '')
                
                if first_train in question or second_train in question:
                    filtered.append(route)
                    
            if filtered:
                logger.info(f"æŒ‰è½¦æ¬¡å·ç­›é€‰ï¼Œæ‰¾åˆ°{len(filtered)}ä¸ªåŒ¹é…æ–¹æ¡ˆ")
                return filtered
        
        # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½ä¸åŒ¹é…ï¼Œå°è¯•ä½¿ç”¨æ›´ä¸€èˆ¬åŒ–çš„å…³é”®è¯åŒ¹é…
        if "çº¿è·¯" in question or "æ–¹æ¡ˆ" in question:
            if "æœ€ä½" in question or "æœ€ä¾¿å®œ" in question:
                logger.info("æ£€æµ‹åˆ°é€šç”¨ä»·æ ¼ç›¸å…³ç­›é€‰æ¡ä»¶")
                sorted_routes = sorted(data_to_filter, key=lambda x: float(x.get('total_price', float('inf'))))
                
                if "æœ€" in question:
                    if sorted_routes:
                        logger.info(f"æ‰¾åˆ°æœ€ä¾¿å®œçš„ä¸­è½¬æ–¹æ¡ˆï¼Œæ€»ä»·: {sorted_routes[0].get('total_price')}å…ƒ")
                        return [sorted_routes[0]]
                    else:
                        return []
                else:
                    return sorted_routes
            
            # å¤„ç†"ä¸­è½¬"æˆ–"ç»è¿‡"ç­‰å…³é”®è¯
            elif "ä¸­è½¬" in question or "ç»è¿‡" in question:
                for station in MAJOR_STATIONS:
                    if station in question:
                        logger.info(f"æ£€æµ‹åˆ°é€šç”¨ä¸­è½¬ç«™ç­›é€‰æ¡ä»¶: {station}")
                        filtered = [route for route in data_to_filter if route.get('transfer_station') == station]
                        if filtered:
                            logger.info(f"æ‰¾åˆ°{len(filtered)}ä¸ªç»è¿‡{station}çš„ä¸­è½¬æ–¹æ¡ˆ")
                            return filtered
        
        # é»˜è®¤è¿”å›åŸå§‹æ•°æ®
        logger.info("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„ç­›é€‰æ¡ä»¶ï¼Œè¿”å›åŸå§‹æ•°æ®")
        return data_to_filter

    def _handle_transfer_query(self, e_context):
        """å¤„ç†ä¸­è½¬æŸ¥è¯¢è¯·æ±‚"""
        logger.info(f"å¼€å§‹å¤„ç†ä¸­è½¬æŸ¥è¯¢: {self.content}")
        
        # è®¾ç½®æŸ¥è¯¢ç±»å‹æ ‡è®°ï¼Œä»¥ä¾¿åç»­ç­›é€‰åŒºåˆ†å¤„ç†
        self.original_query = self.content
        self.is_transfer_query = True  # æ ‡è®°ä¸ºä¸­è½¬æŸ¥è¯¢
        
        try:
            # è§£ææŸ¥è¯¢å‚æ•°
            content = self.content
            
            # è§£æè‡ªç„¶è¯­è¨€ä¸­è½¬æŸ¥è¯¢
            is_natural_language = False
            if not content.startswith("ä¸­è½¬+") and ("ä¸­è½¬" in content or "æ¢ä¹˜" in content):
                is_natural_language = True
                logger.info("æ£€æµ‹åˆ°è‡ªç„¶è¯­è¨€ä¸­è½¬æŸ¥è¯¢ï¼Œå¼€å§‹è§£æ")
                
                # é¦–å…ˆå°è¯•ä½¿ç”¨OpenAIè¿›è¡Œè§£æ
                if USE_OPENAI and OPENAI_API_KEY:
                    logger.info("====== å°è¯•ä½¿ç”¨OpenAIè§£æä¸­è½¬æŸ¥è¯¢ ======")
                    logger.info(f"APIå¯†é’¥çŠ¶æ€: {'å·²é…ç½®' if OPENAI_API_KEY else 'æœªé…ç½®'}")
                    logger.info(f"APIåŸºç¡€URL: {OPENAI_API_BASE}")
                    logger.info(f"ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
                    
                    # è°ƒç”¨OpenAIè§£æ
                    ai_result = self._ai_parse_transfer_query(content)
                    if ai_result:
                        logger.info("OpenAIæˆåŠŸè§£æä¸­è½¬æŸ¥è¯¢")
                        ticket_type, from_loc, to_loc, query_date, query_time, user_specified_transfer = ai_result
                    else:
                        logger.warning("OpenAIè§£æå¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼è§£æ")
                        ticket_type, from_loc, to_loc, query_date, query_time, user_specified_transfer = self._parse_natural_transfer_query(content)
                else:
                    logger.info("OpenAIæœªé…ç½®æˆ–ç¦ç”¨ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ")
                    ticket_type, from_loc, to_loc, query_date, query_time, user_specified_transfer = self._parse_natural_transfer_query(content)
                
                if ticket_type and from_loc and to_loc:
                    logger.info(f"è‡ªç„¶è¯­è¨€è§£æç»“æœ: è½¦å‹={ticket_type}, å‡ºå‘={from_loc}, ç›®çš„åœ°={to_loc}, "
                              f"æ—¥æœŸ={query_date}, æ—¶é—´={query_time or 'å…¨å¤©'}, æŒ‡å®šä¸­è½¬ç«™={user_specified_transfer or 'æ— '}")
                else:
                    self._send_error("æ— æ³•è§£æä¸­è½¬æŸ¥è¯¢ï¼Œè¯·ä½¿ç”¨æ ¼å¼: ä¸­è½¬+é«˜é“ ä¸Šæµ· æˆéƒ½ 2024-03-15", e_context)
                    return
            else:
                # æ ‡å‡†æ ¼å¼è§£æ
                logger.info("ä½¿ç”¨æ ‡å‡†æ ¼å¼è§£æä¸­è½¬æŸ¥è¯¢")
                
                # å¦‚æœæŸ¥è¯¢ä»¥"ä¸­è½¬+"å¼€å¤´ï¼Œå»æ‰è¿™ä¸ªå‰ç¼€
                if content.startswith("ä¸­è½¬+"):
                    content = content[3:]
                
                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æŒ‡å®šäº†ä¸­è½¬ç«™
                user_specified_transfer = None
                for station in MAJOR_STATIONS:
                    if f"ç»{station}" in content or f"é€šè¿‡{station}" in content or f"ä»{station}ä¸­è½¬" in content:
                        user_specified_transfer = station
                        logger.info(f"ç”¨æˆ·æŒ‡å®šä¸­è½¬ç«™: {station}")
                        content = content.replace(f"ç»{station}", "").replace(f"é€šè¿‡{station}", "").replace(f"ä»{station}ä¸­è½¬", "")
                        break
                
                # æŒ‰ç…§æ ‡å‡†æ ¼å¼è§£ææŸ¥è¯¢å‚æ•°
                parts = content.strip().split()
                
                if len(parts) < 3:
                    self._send_error("ä¸­è½¬æŸ¥è¯¢å‚æ•°ä¸è¶³ï¼Œè¯·è‡³å°‘æä¾›è½¦å‹ã€å‡ºå‘åœ°å’Œç›®çš„åœ°", e_context)
                    return
                    
                # è§£æå‚æ•°
                ticket_type = parts[0]
                from_loc = parts[1]
                to_loc = parts[2]
                
                # è·å–å½“å‰æ—¶é—´ä½œä¸ºé»˜è®¤å€¼
                now = datetime.now()
                query_date = now.strftime("%Y-%m-%d")
                query_time = None
                
                # å¤„ç†å¯é€‰å‚æ•°
                if len(parts) >= 4:
                    if re.match(r"\d{4}-\d{2}-\d{2}", parts[3]):
                        query_date = parts[3]
                    elif re.match(r"\d{1,2}:\d{2}", parts[3]):
                        query_time = parts[3]
                        
                if len(parts) >= 5:
                    if re.match(r"\d{1,2}:\d{2}", parts[4]):
                        query_time = parts[4]
            
            logger.info(f"ä¸­è½¬æŸ¥è¯¢å‚æ•°: è½¦å‹={ticket_type}, å‡ºå‘={from_loc}, ç›®çš„åœ°={to_loc}, "
                      f"æ—¥æœŸ={query_date}, æ—¶é—´={query_time or 'å…¨å¤©'}")
            
            # æ¸…ç©ºä¹‹å‰çš„æŸ¥è¯¢ç»“æœ
            self.original_data = []
            self.total_data = []
            self.current_page = 1
            
            # ç¡®å®šä¸­è½¬ç«™
            transfer_stations = self._find_transfer_stations(from_loc, to_loc, user_specified_transfer)
            if not transfer_stations:
                self._send_error(f"æ— æ³•æ‰¾åˆ°ä»{from_loc}åˆ°{to_loc}çš„åˆé€‚ä¸­è½¬ç«™", e_context)
                return
                
            logger.info(f"å°†å°è¯•ä»¥ä¸‹ä¸­è½¬ç«™: {', '.join(transfer_stations)}")
            
            # æŸ¥è¯¢ä¸­è½¬è·¯çº¿
            transfer_routes = self._search_transfer_routes(
                ticket_type, from_loc, to_loc, transfer_stations, query_date, query_time
            )
            
            if not transfer_routes:
                self._send_error(f"æœªæ‰¾åˆ°ä»{from_loc}ç»ä¸­è½¬ç«™åˆ°{to_loc}çš„å¯è¡Œè·¯çº¿", e_context)
                return
                
            # ä¿å­˜ç»“æœåˆ°original_dataå’Œtotal_data
            self.original_data = transfer_routes
            self.total_data = transfer_routes.copy()  # ä½¿ç”¨å‰¯æœ¬ï¼Œé¿å…å¼•ç”¨ç›¸åŒå¯¹è±¡
            logger.info(f"å·²ä¿å­˜{len(transfer_routes)}æ¡ä¸­è½¬æŸ¥è¯¢ç»“æœ")
            
            # æ ¼å¼åŒ–å¹¶å‘é€å“åº”
            reply = Reply()
            reply.type = ReplyType.TEXT
            reply.content = self._format_transfer_response(transfer_routes)
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS
            
        except Exception as e:
            logger.error(f"å¤„ç†ä¸­è½¬æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
            logger.error(traceback.format_exc())
            self._send_error("ä¸­è½¬æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", e_context)

    def _ai_parse_query(self, query):
        """ä½¿ç”¨OpenAIè§£æè‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        if not USE_OPENAI or not OPENAI_API_KEY:
            logger.warning("OpenAIé…ç½®æ— æ•ˆï¼Œæ— æ³•ä½¿ç”¨AIè§£æ")
            return None
            
        logger.info(f"å¼€å§‹ä½¿ç”¨OpenAIè§£ææŸ¥è¯¢: {query}")
        
        try:
            # å¼ºåˆ¶é‡æ–°é…ç½®OpenAI
            openai.api_key = OPENAI_API_KEY
            openai.api_base = OPENAI_API_BASE
            
            # éªŒè¯OpenAIé…ç½®
            logger.info(f"OpenAIé…ç½®éªŒè¯ - APIå¯†é’¥å‰8ä½: {OPENAI_API_KEY[:8]}...")
            logger.info(f"OpenAIé…ç½®éªŒè¯ - APIåŸºç¡€URL: {OPENAI_API_BASE}")
            logger.info(f"OpenAIé…ç½®éªŒè¯ - æ¨¡å‹: {OPENAI_MODEL}")
            
            # è·å–å½“å‰æ—¥æœŸä¿¡æ¯ï¼Œä¾›æç¤ºä¸­ä½¿ç”¨
            now = datetime.now()
            today_date = now.strftime("%Y-%m-%d")
            tomorrow_date = (now + timedelta(days=1)).strftime("%Y-%m-%d")
            day_after_tomorrow_date = (now + timedelta(days=2)).strftime("%Y-%m-%d")
            
            # è®¡ç®—æœ¬å‘¨å’Œä¸‹å‘¨çš„å„å¤©æ—¥æœŸ
            weekday_today = now.weekday()  # 0æ˜¯å‘¨ä¸€ï¼Œ6æ˜¯å‘¨æ—¥
            
            # è®¡ç®—æœ¬å‘¨å„å¤©çš„æ—¥æœŸ
            this_week_dates = {}
            for i in range(7):
                day_offset = i - weekday_today  # ç›¸å¯¹äºä»Šå¤©çš„åç§»
                date = (now + timedelta(days=day_offset)).strftime("%Y-%m-%d")
                this_week_dates[i] = date  # 0->å‘¨ä¸€, 1->å‘¨äºŒ, ...
                
            # è®¡ç®—ä¸‹å‘¨å„å¤©çš„æ—¥æœŸ
            next_week_dates = {}
            for i in range(7):
                day_offset = i - weekday_today + 7  # åŠ 7è¡¨ç¤ºä¸‹ä¸€å‘¨
                date = (now + timedelta(days=day_offset)).strftime("%Y-%m-%d")
                next_week_dates[i] = date
                
            # å½“å‰æ—¥æœŸä¿¡æ¯
            current_date_info = f"""
            ä»Šå¤©æ˜¯ {today_date}ï¼Œæ˜¯{['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][weekday_today]}
            æ˜å¤©æ˜¯ {tomorrow_date}
            åå¤©æ˜¯ {day_after_tomorrow_date}
            æœ¬å‘¨ä¸€æ˜¯ {this_week_dates[0]}
            æœ¬å‘¨äºŒæ˜¯ {this_week_dates[1]}
            æœ¬å‘¨ä¸‰æ˜¯ {this_week_dates[2]}
            æœ¬å‘¨å››æ˜¯ {this_week_dates[3]}
            æœ¬å‘¨äº”æ˜¯ {this_week_dates[4]}
            æœ¬å‘¨å…­æ˜¯ {this_week_dates[5]}
            æœ¬å‘¨æ—¥æ˜¯ {this_week_dates[6]}
            ä¸‹å‘¨ä¸€æ˜¯ {next_week_dates[0]}
            ä¸‹å‘¨äºŒæ˜¯ {next_week_dates[1]}
            ä¸‹å‘¨ä¸‰æ˜¯ {next_week_dates[2]}
            ä¸‹å‘¨å››æ˜¯ {next_week_dates[3]}
            ä¸‹å‘¨äº”æ˜¯ {next_week_dates[4]}
            ä¸‹å‘¨å…­æ˜¯ {next_week_dates[5]}
            ä¸‹å‘¨æ—¥æ˜¯ {next_week_dates[6]}
            """
            
            # æ„å»ºæç¤º
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹é«˜é“ç¥¨æŸ¥è¯¢è¯·æ±‚ï¼Œå¹¶æå–å‡ºå…³é”®ä¿¡æ¯ï¼š"{query}"
            
            è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„ç»“æœï¼ˆä»…è¿”å›æ ¼å¼åŒ–ç»“æœï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šï¼‰ï¼š
            è½¦å‹ å‡ºå‘åŸå¸‚ ç›®çš„åŸå¸‚ æ—¥æœŸ [æ—¶é—´]
            
            å½“å‰æ—¥æœŸä¿¡æ¯ï¼š
            {current_date_info}
            
            è¯·ä½¿ç”¨å‡†ç¡®çš„æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰ï¼š
            - å¯¹äº"ä»Šå¤©"ï¼Œä½¿ç”¨ {today_date}
            - å¯¹äº"æ˜å¤©"ï¼Œä½¿ç”¨ {tomorrow_date}
            - å¯¹äº"åå¤©"ï¼Œä½¿ç”¨ {day_after_tomorrow_date}
            - å¯¹äº"ä¸‹å‘¨ä¸€"ï¼Œä½¿ç”¨ {next_week_dates[0]}
            - å¯¹äº"ä¸‹å‘¨äº”"ï¼Œä½¿ç”¨ {next_week_dates[4]}
            
            ç¤ºä¾‹æŸ¥è¯¢å’Œè§£æï¼š
            æŸ¥è¯¢ï¼š"æ˜å¤©ä¸Šæµ·åˆ°åŒ—äº¬çš„é«˜é“"
            è§£æç»“æœï¼šé«˜é“ ä¸Šæµ· åŒ—äº¬ {tomorrow_date}
            
            æŸ¥è¯¢ï¼š"åå¤©ä¸‹åˆ3ç‚¹ä»æˆéƒ½å»é‡åº†çš„åŠ¨è½¦"
            è§£æç»“æœï¼šåŠ¨è½¦ æˆéƒ½ é‡åº† {day_after_tomorrow_date} 15:00
            
            æŸ¥è¯¢ï¼š"ä¸‹å‘¨ä¸‰ä¸Šåˆ10ç‚¹æ­¦æ±‰åˆ°é•¿æ²™çš„é«˜é“"
            è§£æç»“æœï¼šé«˜é“ æ­¦æ±‰ é•¿æ²™ {next_week_dates[2]} 10:00
            """
            
            # è¾“å‡ºè¯·æ±‚ä¿¡æ¯
            logger.info(f"OpenAIè¯·æ±‚ï¼šæ¨¡å‹={OPENAI_MODEL}, prompté•¿åº¦={len(prompt)}")
            
            # å°è¯•å¤šç§æ–¹å¼è°ƒç”¨OpenAI API
            result_text = ""
            
            # æ ‡å‡†Pythonåº“æ–¹æ³•å¤±è´¥åå°è¯•ç›´æ¥ä½¿ç”¨requestsè°ƒç”¨API
            all_standard_methods_failed = False
            
            try:
                # ç¬¬ä¸€ç§æ–¹å¼ï¼šæ ‡å‡†ChatCompletion API
                logger.info("å°è¯•ä½¿ç”¨æ ‡å‡†ChatCompletion API")
                response = openai.ChatCompletion.create(
                    model=OPENAI_MODEL,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=50
                )
                logger.info("APIè°ƒç”¨æˆåŠŸ!")
                result_text = response.choices[0].message.content.strip()
                
            except AttributeError as attr_error:
                logger.warning(f"æ ‡å‡†APIä¸å¯ç”¨: {attr_error}")
                
                try:
                    # ç¬¬äºŒç§æ–¹å¼ï¼šæœ€æ–°å®¢æˆ·ç«¯æ ¼å¼
                    logger.info("å°è¯•ä½¿ç”¨æœ€æ–°å®¢æˆ·ç«¯æ ¼å¼")
                    response = openai.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                        max_tokens=50
                    )
                    logger.info("æœ€æ–°å®¢æˆ·ç«¯APIè°ƒç”¨æˆåŠŸ!")
                    result_text = response.choices[0].message.content.strip()
                    
                except Exception as latest_error:
                    logger.warning(f"æœ€æ–°å®¢æˆ·ç«¯APIè°ƒç”¨å¤±è´¥: {latest_error}")
                    
                    try:
                        # ç¬¬ä¸‰ç§æ–¹å¼ï¼šæ—§ç‰ˆCompletion API
                        logger.info("å°è¯•ä½¿ç”¨æ—§ç‰ˆCompletion API")
                        response = openai.Completion.create(
                            model=OPENAI_MODEL,
                            prompt=prompt,
                            temperature=0.3,
                            max_tokens=50
                        )
                        logger.info("æ—§ç‰ˆAPIè°ƒç”¨æˆåŠŸ!")
                        result_text = response.choices[0].text.strip()
                    except Exception as old_api_error:
                        logger.error(f"æ‰€æœ‰æ ‡å‡†APIè°ƒç”¨æ–¹å¼å‡å¤±è´¥: {old_api_error}")
                        all_standard_methods_failed = True
            
            except Exception as api_error:
                logger.error(f"APIè°ƒç”¨å¤±è´¥: {api_error}")
                logger.error(traceback.format_exc())
                all_standard_methods_failed = True
                
            # å¦‚æœæ‰€æœ‰æ ‡å‡†æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨requests
            if all_standard_methods_failed:
                logger.info("å°è¯•ä½¿ç”¨ç›´æ¥HTTPè¯·æ±‚è°ƒç”¨OpenAI API")
                try:
                    # æ„å»ºè¯·æ±‚URL - ç¡®ä¿URLæ ¼å¼æ­£ç¡®
                    api_base = OPENAI_API_BASE
                    # ç§»é™¤æœ«å°¾çš„æ–œæ ä»¥é¿å…åŒæ–œæ 
                    if api_base.endswith("/"):
                        api_base = api_base[:-1]
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ ç‰ˆæœ¬è·¯å¾„
                    if "v1" not in api_base.split("/")[-1]:
                        api_url = f"{api_base}/chat/completions"
                    else:
                        api_url = f"{api_base}/chat/completions"
                    
                    logger.info(f"è¯·æ±‚URL: {api_url}")
                    
                    # æ„å»ºè¯·æ±‚å¤´
                    headers = {
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {OPENAI_API_KEY}"
                    }
                    
                    # æ„å»ºè¯·æ±‚æ•°æ®
                    payload = {
                        "model": OPENAI_MODEL,
                        "messages": [{"role": "user", "content": prompt}],
                        "temperature": 0.3,
                        "max_tokens": 50
                    }
                    
                    logger.info(f"å‘é€HTTPè¯·æ±‚åˆ°OpenAI API - è¯¦ç»†è¯·æ±‚æ•°æ®: {json.dumps(payload, ensure_ascii=False)}")
                    response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                    
                    # æ£€æŸ¥å“åº”çŠ¶æ€
                    logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
                    if response.status_code == 200:
                        response_json = response.json()
                        logger.info(f"APIå“åº”å†…å®¹: {json.dumps(response_json, ensure_ascii=False)}")
                        result_text = response_json["choices"][0]["message"]["content"].strip()
                        logger.info(f"HTTPè¯·æ±‚æˆåŠŸè·å–åˆ°ç»“æœ: {result_text}")
                    else:
                        logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {response.text}")
                except Exception as req_error:
                    logger.error(f"HTTPè¯·æ±‚å‡ºé”™: {req_error}")
                    logger.error(traceback.format_exc())
            
            if not result_text:
                logger.warning("OpenAIè¿”å›ç©ºç»“æœ")
                return None
                
            logger.info(f"OpenAIè¿”å›: {result_text}")
            
            # éªŒè¯ç»“æœæ ¼å¼
            parts = result_text.split()
            if len(parts) < 3:
                logger.warning(f"OpenAIè¿”å›æ ¼å¼ä¸æ­£ç¡®: {result_text}")
                return None
            
            # ç¡®ä¿è‡³å°‘åŒ…å«è½¦å‹ã€å‡ºå‘åŸå¸‚å’Œç›®çš„åŸå¸‚
            logger.info(f"è§£æç»“æœ: è½¦å‹={parts[0]}, å‡ºå‘åŸå¸‚={parts[1]}, ç›®çš„åŸå¸‚={parts[2]}")
            
            # å¦‚æœæœ‰æ—¥æœŸéƒ¨åˆ†ï¼Œç¡®ä¿æ—¥æœŸæ˜¯æ­£ç¡®çš„æ ¼å¼
            if len(parts) >= 4:
                date_part = parts[3]
                # æ£€æŸ¥æ—¥æœŸæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœä¸æ­£ç¡®ï¼Œå°è¯•è§£æç›¸å¯¹æ—¥æœŸè¡¨è¾¾
                if not re.match(r"\d{4}-\d{2}-\d{2}", date_part):
                    # ä½¿ç”¨æˆ‘ä»¬å·²è®¡ç®—çš„æ—¥æœŸä¿¡æ¯ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                    if "ä»Šå¤©" in query:
                        parts[3] = today_date
                    elif "æ˜å¤©" in query:
                        parts[3] = tomorrow_date
                    elif "åå¤©" in query:
                        parts[3] = day_after_tomorrow_date
                    elif "ä¸‹å‘¨ä¸€" in query or "ä¸‹ç¤¼æ‹œä¸€" in query:
                        parts[3] = next_week_dates[0]
                    elif "ä¸‹å‘¨äºŒ" in query or "ä¸‹ç¤¼æ‹œäºŒ" in query:
                        parts[3] = next_week_dates[1]
                    elif "ä¸‹å‘¨ä¸‰" in query or "ä¸‹ç¤¼æ‹œä¸‰" in query:
                        parts[3] = next_week_dates[2]
                    elif "ä¸‹å‘¨å››" in query or "ä¸‹ç¤¼æ‹œå››" in query:
                        parts[3] = next_week_dates[3]
                    elif "ä¸‹å‘¨äº”" in query or "ä¸‹ç¤¼æ‹œäº”" in query:
                        parts[3] = next_week_dates[4]
                    elif "ä¸‹å‘¨å…­" in query or "ä¸‹ç¤¼æ‹œå…­" in query:
                        parts[3] = next_week_dates[5]
                    elif "ä¸‹å‘¨æ—¥" in query or "ä¸‹ç¤¼æ‹œæ—¥" in query or "ä¸‹å‘¨å¤©" in query:
                        parts[3] = next_week_dates[6]
                    elif "å‘¨ä¸€" in query or "ç¤¼æ‹œä¸€" in query:
                        parts[3] = this_week_dates[0]
                    elif "å‘¨äºŒ" in query or "ç¤¼æ‹œäºŒ" in query:
                        parts[3] = this_week_dates[1]
                    elif "å‘¨ä¸‰" in query or "ç¤¼æ‹œä¸‰" in query:
                        parts[3] = this_week_dates[2]
                    elif "å‘¨å››" in query or "ç¤¼æ‹œå››" in query:
                        parts[3] = this_week_dates[3]
                    elif "å‘¨äº”" in query or "ç¤¼æ‹œäº”" in query:
                        parts[3] = this_week_dates[4]
                    elif "å‘¨å…­" in query or "ç¤¼æ‹œå…­" in query:
                        parts[3] = this_week_dates[5]
                    elif "å‘¨æ—¥" in query or "ç¤¼æ‹œæ—¥" in query or "å‘¨å¤©" in query:
                        parts[3] = this_week_dates[6]
                    else:
                        parts[3] = today_date  # é»˜è®¤ä½¿ç”¨ä»Šå¤©
                    logger.info(f"ä¿®æ­£æ—¥æœŸä¸º: {parts[3]}")
            
            # è¿”å›ä¿®æ­£åçš„æ ¼å¼åŒ–ç»“æœ
            return " ".join(parts)
                
        except Exception as e:
            logger.error(f"OpenAIè§£æå¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            return None

    def _ai_parse_transfer_query(self, query):
        """ä½¿ç”¨OpenAIè§£æä¸­è½¬æŸ¥è¯¢"""
        logger.info(f"ä½¿ç”¨OpenAIè§£æä¸­è½¬æŸ¥è¯¢: {query}")
        
        try:
            # é…ç½®OpenAIå®¢æˆ·ç«¯
            logger.info(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯...")
            logger.info(f"APIå¯†é’¥: {OPENAI_API_KEY[:8]}...")
            logger.info(f"APIåŸºç¡€URL: {OPENAI_API_BASE}")
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
            
            # å¼ºåˆ¶é‡æ–°é…ç½®OpenAI
            openai.api_key = OPENAI_API_KEY
            openai.api_base = OPENAI_API_BASE
            
            # è·å–å½“å‰æ—¥æœŸ
            now = datetime.now()
            today = now.strftime("%Y-%m-%d")
            tomorrow = (now + timedelta(days=1)).strftime("%Y-%m-%d")
            day_after_tomorrow = (now + timedelta(days=2)).strftime("%Y-%m-%d")
            
            # æ„å»ºæç¤º
            prompt = f"""
            ä»Šå¤©æ—¥æœŸæ˜¯ {today}ã€‚
            
            è¯·è§£æä»¥ä¸‹ä¸­è½¬æŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š
            "{query}"
            
            1. è½¦å‹ï¼ˆé«˜é“/åŠ¨è½¦/æ™®é€šï¼Œé»˜è®¤ä¸ºé«˜é“ï¼‰
            2. å‡ºå‘åŸå¸‚
            3. ç›®çš„åœ°åŸå¸‚
            4. æ—¥æœŸï¼ˆæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœæ˜¯"æ˜å¤©"åˆ™ä¸º {tomorrow}ï¼Œ"åå¤©"åˆ™ä¸º {day_after_tomorrow}ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™é»˜è®¤ä¸ºä»Šå¤©ï¼‰
            5. æ—¶é—´ï¼ˆå¦‚"ä¸Šåˆ9ç‚¹"ã€"ä¸‹åˆ2ç‚¹"ç­‰ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä¸ºç©ºï¼‰
            6. æŒ‡å®šä¸­è½¬ç«™ï¼ˆå¦‚æœç”¨æˆ·æŒ‡å®šäº†ä¸­è½¬ç«™ï¼Œå¦‚"ç»æ­¦æ±‰"ã€"é€šè¿‡éƒ‘å·"ç­‰ï¼‰
            
            è¿”å›JSONæ ¼å¼ï¼š
            {{
              "ticket_type": "é«˜é“/åŠ¨è½¦/æ™®é€š",
              "from_loc": "å‡ºå‘åŸå¸‚",
              "to_loc": "ç›®çš„åœ°åŸå¸‚", 
              "date": "YYYY-MM-DD",
              "time": "HH:MMæˆ–ç©º",
              "transfer_station": "ä¸­è½¬ç«™æˆ–null"
            }}
            
            åªè¿”å›JSONï¼Œä¸éœ€è¦è§£é‡Šã€‚å¦‚æœæ— æ³•è§£ææŸé¡¹ï¼Œå¯¹åº”å€¼è®¾ä¸ºnullã€‚
            """
            
            # è°ƒç”¨OpenAI API
            logger.info(f"æ­£åœ¨è°ƒç”¨OpenAI API - ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
            
            try:
                # æ–°ç‰ˆAPIè°ƒç”¨
                logger.info("å°è¯•ä½¿ç”¨æ–°ç‰ˆOpenAI API (ChatCompletion)")
                response = openai.ChatCompletion.create(
                    model=OPENAI_MODEL,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=500
                )
                logger.info("æ–°ç‰ˆAPIè°ƒç”¨æˆåŠŸ!")
                result_text = response.choices[0].message.content.strip()
                
            except AttributeError:
                try:
                    # æœ€æ–°å®¢æˆ·ç«¯æ ¼å¼
                    logger.info("å°è¯•ä½¿ç”¨æœ€æ–°å®¢æˆ·ç«¯æ ¼å¼")
                    response = openai.chat.completions.create(
                        model=OPENAI_MODEL,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                        max_tokens=500
                    )
                    logger.info("æœ€æ–°å®¢æˆ·ç«¯APIè°ƒç”¨æˆåŠŸ!")
                    result_text = response.choices[0].message.content.strip()
                    
                except Exception as latest_error:
                    logger.warning(f"æœ€æ–°å®¢æˆ·ç«¯APIè°ƒç”¨å¤±è´¥: {latest_error}")
                    logger.info("å°è¯•ä½¿ç”¨æ—§ç‰ˆOpenAI API (Completion)")
                    response = openai.Completion.create(
                        model=OPENAI_MODEL,
                        prompt=prompt,
                        temperature=0.3,
                        max_tokens=500
                    )
                    logger.info("æ—§ç‰ˆAPIè°ƒç”¨æˆåŠŸ!")
                    result_text = response.choices[0].text.strip()
            
            # æ£€æŸ¥å¹¶å»é™¤markdownä»£ç å—æ ¼å¼
            if result_text.startswith("```"):
                logger.info("æ£€æµ‹åˆ°è¿”å›å†…å®¹åŒ…å«markdownä»£ç å—æ ¼å¼ï¼Œæ­£åœ¨ç§»é™¤...")
                pattern = r"```(?:json)?\s*([\s\S]*?)```"
                match = re.search(pattern, result_text)
                if match:
                    result_text = match.group(1).strip()
                    logger.info(f"ç§»é™¤markdownæ ¼å¼åçš„å†…å®¹: {result_text[:100]}...")
            
            # è§£æJSONå“åº”
            result_json = json.loads(result_text)
            logger.info(f"OpenAIè§£æç»“æœ: {json.dumps(result_json, ensure_ascii=False)}")
            
            # æå–ç»“æœ
            ticket_type = result_json.get("ticket_type")
            from_loc = result_json.get("from_loc")
            to_loc = result_json.get("to_loc")
            date = result_json.get("date")
            time = result_json.get("time")
            transfer_station = result_json.get("transfer_station")
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if ticket_type and from_loc and to_loc:
                logger.info("OpenAIæˆåŠŸè§£æå‡ºå¿…è¦å­—æ®µ")
                return ticket_type, from_loc, to_loc, date, time, transfer_station
            else:
                logger.warning("OpenAIè§£æç»“æœç¼ºå°‘å¿…è¦å­—æ®µ")
                return None
                
        except Exception as e:
            logger.error(f"OpenAIè§£æä¸­è½¬æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return None

    def _parse_natural_transfer_query(self, query):
        """è§£æè‡ªç„¶è¯­è¨€ä¸­è½¬æŸ¥è¯¢"""
        logger.info(f"è§£æè‡ªç„¶è¯­è¨€ä¸­è½¬æŸ¥è¯¢: {query}")
        
        # é»˜è®¤å€¼
        ticket_type = "é«˜é“"  # é»˜è®¤é«˜é“
        from_loc = None
        to_loc = None
        query_date = None
        query_time = None
        user_specified_transfer = None
        
        try:
            # 1. æå–è½¦å‹
            if "åŠ¨è½¦" in query:
                ticket_type = "åŠ¨è½¦"
            elif "æ™®é€š" in query:
                ticket_type = "æ™®é€š"
            
            # 2. æå–åŸå¸‚ - æ”¯æŒå¤šç§è¡¨è¾¾æ–¹å¼
            # åŒ¹é…æ¨¡å¼1ï¼šä»Aåˆ°B
            location_pattern1 = r"ä»([\u4e00-\u9fa5]+)åˆ°([\u4e00-\u9fa5]+)"
            # åŒ¹é…æ¨¡å¼2ï¼šAåˆ°B / Aè‡³B / Aå»B
            location_pattern2 = r"([\u4e00-\u9fa5]+)(?:åˆ°|è‡³|å»)([\u4e00-\u9fa5]+)"
            
            # å…ˆå¤„ç†æ—¥æœŸå’Œæ—¶é—´çŸ­è¯­
            time_keywords = ["ä»Šå¤©", "æ˜å¤©", "åå¤©", "ä¸‹åˆ", "ä¸Šåˆ", "æ™šä¸Š", "å‡Œæ™¨", "ä¸­åˆ", "æ—©ä¸Š"]
            cleaned_content = query
            for keyword in time_keywords:
                cleaned_content = cleaned_content.replace(keyword, " " + keyword + " ")
            
            logger.info(f"é¢„å¤„ç†åçš„æŸ¥è¯¢å†…å®¹ï¼š{cleaned_content}")
            
            # åœ¨é¢„å¤„ç†åçš„å†…å®¹ä¸­æŸ¥æ‰¾åŸå¸‚
            location_match = re.search(location_pattern1, cleaned_content)
            if not location_match:
                location_match = re.search(location_pattern2, cleaned_content)
                
            if not location_match:
                logger.warning("æœªæ‰¾åˆ°å‡ºå‘åœ°å’Œç›®çš„åœ°")
                return None, None, None, None, None, None
                
            from_loc = location_match.group(1).strip()
            to_loc = location_match.group(2).strip()
            
            # æ¸…é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬å’Œæ—¶é—´è¯
            for keyword in time_keywords:
                from_loc = from_loc.replace(keyword, "").strip()
                to_loc = to_loc.replace(keyword, "").strip()
                
            # æ¸…é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬
            to_loc = to_loc.split("çš„")[0].strip() if "çš„" in to_loc else to_loc
            
            logger.info(f"è¯†åˆ«åˆ°åŸå¸‚ï¼š{from_loc} -> {to_loc}")
            
            # 3. æå–ä¸­è½¬ç«™
            for station in MAJOR_STATIONS:
                if f"ç»{station}" in query or f"é€šè¿‡{station}" in query or f"ä»{station}ä¸­è½¬" in query or f"åœ¨{station}ä¸­è½¬" in query:
                    user_specified_transfer = station
                    logger.info(f"è¯†åˆ«åˆ°ç”¨æˆ·æŒ‡å®šä¸­è½¬ç«™: {station}")
                    break
            
            # 4. å¤„ç†æ—¶é—´
            now = datetime.now()
            query_date = now.strftime("%Y-%m-%d")  # é»˜è®¤ä»Šå¤©
            
            # å¤„ç†æ—¥æœŸ
            if "æ˜å¤©" in query:
                query_date = (now + timedelta(days=1)).strftime("%Y-%m-%d")
                logger.info(f"è¯†åˆ«åˆ°æ—¥æœŸï¼šæ˜å¤© ({query_date})")
            elif "åå¤©" in query:
                query_date = (now + timedelta(days=2)).strftime("%Y-%m-%d")
                logger.info(f"è¯†åˆ«åˆ°æ—¥æœŸï¼šåå¤© ({query_date})")
            else:
                logger.info(f"ä½¿ç”¨é»˜è®¤æ—¥æœŸï¼šä»Šå¤© ({query_date})")
                
            # å¤„ç†å…·ä½“æ—¶é—´
            time_pattern = r"(\d{1,2})(?:ç‚¹|æ—¶|:|ï¼š)(\d{0,2})(?:åˆ†|)|(\d{1,2})(?:ç‚¹|æ—¶)"
            time_match = re.search(time_pattern, query)
            
            if time_match:
                if time_match.group(3):  # åŒ¹é…äº†"3ç‚¹"è¿™ç§æ ¼å¼
                    hour = int(time_match.group(3))
                    minute = 0
                else:  # åŒ¹é…äº†"3:30"æˆ–"3ç‚¹30åˆ†"è¿™ç§æ ¼å¼
                    hour = int(time_match.group(1))
                    minute = int(time_match.group(2)) if time_match.group(2) else 0
                
                # å¤„ç†12å°æ—¶åˆ¶è½¬24å°æ—¶åˆ¶
                if "ä¸‹åˆ" in query or "æ™šä¸Š" in query:
                    if hour < 12:
                        hour += 12
                        
                query_time = f"{hour:02d}:{minute:02d}"
                logger.info(f"æå–åˆ°å…·ä½“æ—¶é—´ï¼š{query_time}")
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°å…·ä½“æ—¶é—´ï¼Œåˆ™å°è¯•æå–æ—¶é—´æ®µ
            if not query_time:
                if "ä¸Šåˆ" in query:
                    query_time = "09:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šä¸Šåˆï¼Œè®¾ç½®ä¸º09:00")
                elif "ä¸‹åˆ" in query and "æ™š" not in query:
                    query_time = "14:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šä¸‹åˆï¼Œè®¾ç½®ä¸º14:00")
                elif "æ™šä¸Š" in query or "å‚æ™š" in query:
                    query_time = "19:00"
                    logger.info("è¯†åˆ«åˆ°æ—¶é—´æ®µï¼šæ™šä¸Šï¼Œè®¾ç½®ä¸º19:00")
            
            return ticket_type, from_loc, to_loc, query_date, query_time, user_specified_transfer
            
        except Exception as e:
            logger.error(f"è‡ªç„¶è¯­è¨€ä¸­è½¬æŸ¥è¯¢è§£æå¤±è´¥ï¼š{e}")
            logger.error(traceback.format_exc())
            return None, None, None, None, None, None

    def _find_transfer_stations(self, from_loc, to_loc, user_specified=None):
        """ç¡®å®šä¸­è½¬ç«™"""
        logger.info(f"å¯»æ‰¾ä»{from_loc}åˆ°{to_loc}çš„ä¸­è½¬ç«™")
        
        # 1. å¦‚æœç”¨æˆ·æŒ‡å®šäº†ä¸­è½¬ç«™ï¼Œä¼˜å…ˆä½¿ç”¨
        if user_specified:
            logger.info(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ä¸­è½¬ç«™: {user_specified}")
            return [user_specified]
            
        # 2. æŸ¥æ‰¾é¢„å®šä¹‰çš„ä¸­è½¬ç«™
        key = (from_loc, to_loc)
        if key in TRANSFER_STATIONS:
            logger.info(f"ä½¿ç”¨é¢„å®šä¹‰çš„ä¸­è½¬ç«™: {TRANSFER_STATIONS[key]}")
            return TRANSFER_STATIONS[key]
            
        # 3. ä½¿ç”¨ä¸»è¦æ¢çº½ç«™ä½œä¸ºå€™é€‰ä¸­è½¬ç«™
        # å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥è°ƒç”¨APIæŸ¥è¯¢æ›´ç²¾ç¡®çš„ä¸­è½¬ç«™
        # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œæš‚æ—¶ä½¿ç”¨ä¸»è¦æ¢çº½ç«™ä¸­çš„å‰5ä¸ª
        # åœ¨å®é™…å®ç°ä¸­ï¼Œåº”è¯¥æ ¹æ®åœ°ç†ä½ç½®å’Œçº¿è·¯ä¼˜åŒ–é€‰æ‹©
        logger.info("æ²¡æœ‰é¢„å®šä¹‰ä¸­è½¬ç«™ï¼Œä½¿ç”¨ä¸»è¦æ¢çº½ç«™ä½œä¸ºå€™é€‰")
        return MAJOR_STATIONS[:5]

    def _search_transfer_routes(self, ticket_type, from_loc, to_loc, transfer_stations, date, time=None):
        """æŸ¥è¯¢ä¸­è½¬è·¯çº¿"""
        logger.info(f"å¼€å§‹æŸ¥è¯¢ä¸­è½¬è·¯çº¿: {from_loc} -> [ä¸­è½¬] -> {to_loc}")
        
        all_routes = []
        min_transfer_time = 30  # æœ€å°æ¢ä¹˜æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        max_transfer_time = 180  # æœ€å¤§æ¢ä¹˜æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        
        for transfer_station in transfer_stations:
            logger.info(f"æŸ¥è¯¢ç»ç”± {transfer_station} çš„ä¸­è½¬è·¯çº¿")
            
            # æŸ¥è¯¢ç¬¬ä¸€æ®µ: å‡ºå‘åœ° -> ä¸­è½¬ç«™
            first_leg = self.get_ticket_info(ticket_type, from_loc, transfer_station, date, time)
            if not first_leg:
                logger.warning(f"æœªæ‰¾åˆ°ä» {from_loc} åˆ° {transfer_station} çš„è½¦æ¬¡")
                continue
                
            logger.info(f"æ‰¾åˆ°ä» {from_loc} åˆ° {transfer_station} çš„è½¦æ¬¡æ•°é‡: {len(first_leg)}")
            
            # æŸ¥è¯¢ç¬¬äºŒæ®µ: ä¸­è½¬ç«™ -> ç›®çš„åœ°
            second_leg = self.get_ticket_info(ticket_type, transfer_station, to_loc, date, None)
            if not second_leg:
                logger.warning(f"æœªæ‰¾åˆ°ä» {transfer_station} åˆ° {to_loc} çš„è½¦æ¬¡")
                continue
                
            logger.info(f"æ‰¾åˆ°ä» {transfer_station} åˆ° {to_loc} çš„è½¦æ¬¡æ•°é‡: {len(second_leg)}")
            
            # åŒ¹é…åˆé€‚çš„ä¸­è½¬æ–¹æ¡ˆ
            for train1 in first_leg:
                arrival_time = train1.get('arrivetime', '')
                if not arrival_time:
                    continue
                    
                arrival_time_obj = datetime.strptime(arrival_time, "%H:%M").time()
                arrival_minutes = arrival_time_obj.hour * 60 + arrival_time_obj.minute
                
                for train2 in second_leg:
                    depart_time = train2.get('departtime', '')
                    if not depart_time:
                        continue
                        
                    depart_time_obj = datetime.strptime(depart_time, "%H:%M").time()
                    depart_minutes = depart_time_obj.hour * 60 + depart_time_obj.minute
                    
                    # è®¡ç®—æ¢ä¹˜æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
                    # å¦‚æœç¬¬äºŒæ®µè½¦æ¬¡æ—¶é—´æ—©äºç¬¬ä¸€æ®µï¼Œåˆ™è®¤ä¸ºæ˜¯ç¬¬äºŒå¤©çš„è½¦æ¬¡
                    transfer_minutes = depart_minutes - arrival_minutes
                    if transfer_minutes < 0:
                        # è·¨å¤©æƒ…å†µï¼ŒåŠ ä¸Š24å°æ—¶
                        transfer_minutes += 24 * 60
                        
                    # åˆ¤æ–­æ¢ä¹˜æ—¶é—´æ˜¯å¦åˆç†
                    if min_transfer_time <= transfer_minutes <= max_transfer_time:
                        # è®¡ç®—æ€»ä»·æ ¼ï¼ˆä»¥äºŒç­‰åº§ä¸ºä¾‹ï¼‰
                        total_price = self._calculate_total_price(train1, train2)
                        
                        # è®¡ç®—æ€»æ—¶é—´
                        total_runtime = self._calculate_total_runtime(train1, train2, transfer_minutes)
                        
                        route = {
                            'first_leg': train1,
                            'second_leg': train2,
                            'transfer_station': transfer_station,
                            'transfer_time': transfer_minutes,
                            'total_price': total_price,
                            'total_runtime': total_runtime
                        }
                        all_routes.append(route)
                        logger.info(f"æ‰¾åˆ°å¯è¡Œçš„ä¸­è½¬æ–¹æ¡ˆ: {train1['trainumber']} -> {train2['trainumber']}, "
                                  f"æ¢ä¹˜æ—¶é—´: {transfer_minutes}åˆ†é’Ÿ, æ€»ä»·æ ¼: {total_price}å…ƒ")
        
        # æŒ‰æ€»æ—¶é—´æ’åº
        all_routes.sort(key=lambda x: x['total_runtime'])
        logger.info(f"å…±æ‰¾åˆ°{len(all_routes)}ä¸ªå¯è¡Œçš„ä¸­è½¬æ–¹æ¡ˆ")
        
        # è¿”å›å‰10ä¸ªæ–¹æ¡ˆ
        return all_routes[:10]

    def _calculate_total_price(self, train1, train2):
        """è®¡ç®—ä¸¤æ®µè¡Œç¨‹çš„æ€»ä»·æ ¼ï¼ˆé»˜è®¤ä»¥äºŒç­‰åº§ä¸ºå‚è€ƒï¼‰"""
        try:
            # æ‰¾å‡ºç¬¬ä¸€æ®µçš„äºŒç­‰åº§ä»·æ ¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¸€ç­‰åº§æˆ–å•†åŠ¡åº§
            price1 = 0
            for seat in train1.get('ticket_info', []):
                if seat.get('seatname') == 'äºŒç­‰åº§':
                    price1 = float(seat.get('seatprice', 0))
                    break
            if price1 == 0:
                # æ‰¾ä¸åˆ°äºŒç­‰åº§ï¼Œå°è¯•å…¶ä»–åº§ä½
                for seat in train1.get('ticket_info', []):
                    if seat.get('seatprice'):
                        price1 = float(seat.get('seatprice', 0))
                        break
            
            # æ‰¾å‡ºç¬¬äºŒæ®µçš„äºŒç­‰åº§ä»·æ ¼
            price2 = 0
            for seat in train2.get('ticket_info', []):
                if seat.get('seatname') == 'äºŒç­‰åº§':
                    price2 = float(seat.get('seatprice', 0))
                    break
            if price2 == 0:
                # æ‰¾ä¸åˆ°äºŒç­‰åº§ï¼Œå°è¯•å…¶ä»–åº§ä½
                for seat in train2.get('ticket_info', []):
                    if seat.get('seatprice'):
                        price2 = float(seat.get('seatprice', 0))
                        break
                        
            return price1 + price2
        except Exception as e:
            logger.error(f"è®¡ç®—æ€»ä»·æ ¼æ—¶å‡ºé”™: {e}")
            return 0

    def _calculate_total_runtime(self, train1, train2, transfer_minutes):
        """è®¡ç®—æ€»è¡Œç¨‹æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        try:
            # è§£æç¬¬ä¸€æ®µè¿è¡Œæ—¶é—´
            runtime1_str = train1.get('runtime', '0å°æ—¶0åˆ†é’Ÿ')
            runtime1 = self._convert_runtime_to_minutes(runtime1_str)
            
            # è§£æç¬¬äºŒæ®µè¿è¡Œæ—¶é—´
            runtime2_str = train2.get('runtime', '0å°æ—¶0åˆ†é’Ÿ')
            runtime2 = self._convert_runtime_to_minutes(runtime2_str)
            
            # æ€»æ—¶é—´ = ç¬¬ä¸€æ®µæ—¶é—´ + æ¢ä¹˜æ—¶é—´ + ç¬¬äºŒæ®µæ—¶é—´
            total_runtime = runtime1 + transfer_minutes + runtime2
            return total_runtime
        except Exception as e:
            logger.error(f"è®¡ç®—æ€»è¡Œç¨‹æ—¶é—´æ—¶å‡ºé”™: {e}")
            return 0

    def _format_transfer_response(self, routes):
        """æ ¼å¼åŒ–ä¸­è½¬æŸ¥è¯¢ç»“æœ"""
        if not routes:
            return "æœªæ‰¾åˆ°åˆé€‚çš„ä¸­è½¬æ–¹æ¡ˆ"
            
        result = ["ã€ä¸­è½¬æŸ¥è¯¢ç»“æœã€‘"]
        
        for idx, route in enumerate(routes, 1):
            first_leg = route['first_leg']
            second_leg = route['second_leg']
            transfer_station = route['transfer_station']
            transfer_time = route['transfer_time']
            total_price = route['total_price']
            
            # è®¡ç®—æ€»æ—¶é—´ï¼Œæ ¼å¼åŒ–ä¸ºå°æ—¶å’Œåˆ†é’Ÿ
            total_minutes = route['total_runtime']
            total_hours = total_minutes // 60
            total_mins = total_minutes % 60
            total_time_str = f"{total_hours}å°æ—¶{total_mins}åˆ†é’Ÿ"
            
            # æ‹¼æ¥ç»“æœ
            route_info = []
            route_info.append(f"\n{idx}. ã€æ€»æ—¶é•¿: {total_time_str}ã€‘ ã€æ€»ç¥¨ä»·: Â¥{total_price}ã€‘")
            
            # ç¬¬ä¸€æ®µè¡Œç¨‹
            route_info.append(f"â‘  {first_leg.get('trainumber')} {first_leg.get('traintype')}: "
                            f"{first_leg.get('departstation')}({first_leg.get('departtime')}) â†’ "
                            f"{transfer_station}({first_leg.get('arrivetime')})")
            
            # æ¢ä¹˜ä¿¡æ¯
            transfer_hours = transfer_time // 60
            transfer_mins = transfer_time % 60
            route_info.append(f"   ğŸ”„ {transfer_station}ç«™å†…æ¢ä¹˜ {transfer_hours}å°æ—¶{transfer_mins}åˆ†é’Ÿ")
            
            # ç¬¬äºŒæ®µè¡Œç¨‹
            route_info.append(f"â‘¡ {second_leg.get('trainumber')} {second_leg.get('traintype')}: "
                            f"{transfer_station}({second_leg.get('departtime')}) â†’ "
                            f"{second_leg.get('arrivestation')}({second_leg.get('arrivetime')})")
            
            # ç¥¨ä»·ä¿¡æ¯
            route_info.append("ğŸ’°ç¥¨ä»·è¯¦æƒ…:")
            route_info.append(f"   ç¬¬ä¸€æ®µ: " + " | ".join([
                f"{s.get('seatname', 'æœªçŸ¥')}ï¼šÂ¥{s.get('seatprice', 'æœªçŸ¥')}ï¼ˆä½™{s.get('seatinventory', 0)}å¼ ï¼‰"
                for s in first_leg.get('ticket_info', [])[:3]  # åªæ˜¾ç¤ºå‰3ç§å¸­åˆ«
            ]))
            route_info.append(f"   ç¬¬äºŒæ®µ: " + " | ".join([
                f"{s.get('seatname', 'æœªçŸ¥')}ï¼šÂ¥{s.get('seatprice', 'æœªçŸ¥')}ï¼ˆä½™{s.get('seatinventory', 0)}å¼ ï¼‰"
                for s in second_leg.get('ticket_info', [])[:3]  # åªæ˜¾ç¤ºå‰3ç§å¸­åˆ«
            ]))
            
            result.append("\n".join(route_info))
        
        # æ·»åŠ é¡µè„š
        footer = "\nğŸ“Œæç¤º: ä»¥ä¸Šä¸ºç³»ç»Ÿæ¨èçš„æœ€ä½³ä¸­è½¬æ–¹æ¡ˆï¼ŒæŒ‰æ€»è€—æ—¶æ’åº"
        footer += "\nğŸ’¡å¦‚éœ€æŒ‡å®šä¸­è½¬ç«™ï¼Œè¯·ä½¿ç”¨æ ¼å¼: ä¸­è½¬+ç»å—äº¬+é«˜é“ æˆéƒ½ ä¸Šæµ·"
        
        return "\n".join(result) + footer

    def _send_error(self, message, e_context):
        """å‘é€é”™è¯¯ä¿¡æ¯"""
        logger.error(f"é”™è¯¯ä¿¡æ¯ï¼š{message}")
        reply = Reply()
        reply.type = ReplyType.ERROR
        reply.content = message
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS

    def _format_train_info(self, trains):
        """æ ¼å¼åŒ–åˆ—è½¦ä¿¡æ¯"""
        if not trains:
            return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è½¦æ¬¡"
            
        result = []
        for train in trains:
            train_info = [
                f"è½¦æ¬¡ï¼š{train['trainumber']}",
                f"å‡ºå‘ï¼š{train['departstation']} {train['departtime']}",
                f"åˆ°è¾¾ï¼š{train['arrivestation']} {train['arrivetime']}",
                f"å†æ—¶ï¼š{train['runtime']}"
            ]
            
            # æ·»åŠ ç¥¨ä»·ä¿¡æ¯
            ticket_info = []
            for ticket in train['ticket_info']:
                status = "âœ…" if ticket['bookable'] == "æœ‰è½¦ç¥¨" else "âŒ"
                ticket_info.append(f"{ticket['seatname']}: {status} Â¥{ticket['seatprice']}")
            
            train_info.append("ç¥¨ä»·ï¼š" + " | ".join(ticket_info))
            result.append("\n".join(train_info))
            
        return "\n\n".join(result)

    def _process_query(self, e_context: EventContext):
        """å¤„ç†æŸ¥è¯¢è¯·æ±‚"""
        query = e_context["query"]
        logger.debug(f"æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚ï¼š{query}")
        
        # è§£ææŸ¥è¯¢å‚æ•°
        ticket_type = "é«˜é“"  # é»˜è®¤æŸ¥è¯¢é«˜é“
        from_loc = "ä¸Šæµ·"
        to_loc = "åŒ—äº¬"
        time = "12:00"  # é»˜è®¤ä¸­åˆ12ç‚¹
        
        # è·å–è½¦ç¥¨ä¿¡æ¯
        trains = self.get_ticket_info(ticket_type, from_loc, to_loc, None, time)
        if trains is None:
            e_context["reply"] = "æŠ±æ­‰ï¼ŒæŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            e_context.action = EventAction.BREAK_PASS
            return
            
        # æ ¼å¼åŒ–ç»“æœ
        reply = self._format_train_info(trains)
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS

    def _convert_runtime_to_minutes(self, runtime_str):
        """å°†è¿è¡Œæ—¶é•¿å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†é’Ÿæ•°"""
        try:
            # å¤„ç†æ ¼å¼å¦‚ "4å°æ—¶31åˆ†é’Ÿ"
            hours = 0
            minutes = 0
            hour_match = re.search(r"(\d+)å°æ—¶", runtime_str)
            if hour_match:
                hours = int(hour_match.group(1))
            minute_match = re.search(r"(\d+)åˆ†é’Ÿ", runtime_str)
            if minute_match:
                minutes = int(minute_match.group(1))
            return hours * 60 + minutes
        except Exception as e:
            logger.error(f"è¿è¡Œæ—¶é—´è½¬æ¢é”™è¯¯ï¼š{runtime_str}, {e}")
            return 0
